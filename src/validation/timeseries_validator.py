#!/usr/bin/env python3
"""
ì‹œê³„ì—´ ê²€ì¦ ì‹œìŠ¤í…œ êµ¬í˜„
- Purged K-Fold=5 + Embargo=í‰ê· ë³´ìœ ê¸°ê°„Ã—2
- foldë³„ Score ë©”ë””ì•ˆ âˆ’ DD íŒ¨ë„í‹° ë­í‚¹
- Top-3 íŒŒë¼ë¯¸í„° ìŠ¹ê¸‰ ì‹œìŠ¤í…œ
- ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ ê²€ì¦ ë¡œì§
"""

import warnings
from dataclasses import dataclass
from typing import Callable, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

warnings.filterwarnings("ignore")

from fast_data_engine import FastDataEngine
from performance_evaluator import PerformanceEvaluator, PerformanceMetrics


@dataclass
class FoldResult:
    """Fold ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""

    fold_id: int
    train_start: int
    train_end: int
    test_start: int
    test_end: int
    metrics: PerformanceMetrics
    score: float
    params: Dict


class TimeSeriesValidator:
    def __init__(self, data_engine: FastDataEngine, performance_evaluator: PerformanceEvaluator):
        """ì‹œê³„ì—´ ê²€ì¦ì ì´ˆê¸°í™”"""
        self.data_engine = data_engine
        self.performance_evaluator = performance_evaluator

        # Purged K-Fold ì„¤ì •
        self.kfold_config = {
            "n_splits": 5,  # K=5
            "test_size": 0.2,  # ê° foldì—ì„œ í…ŒìŠ¤íŠ¸ ë¹„ìœ¨
            "purge_pct": 0.01,  # í¼ì§€ ë¹„ìœ¨ (1%)
            "embargo_multiplier": 2,  # ì— ë°”ê³  = í‰ê· ë³´ìœ ê¸°ê°„ Ã— 2
        }

        # ê²€ì¦ ì„¤ì •
        self.validation_config = {
            "min_test_trades": 20,  # ìµœì†Œ í…ŒìŠ¤íŠ¸ ê±°ë˜ ìˆ˜
            "consistency_threshold": 0.6,  # 60% ì´ìƒ foldì—ì„œ ìˆ˜ìµì„± ìœ ì§€
            "stability_weight": 0.3,  # ì•ˆì •ì„± ê°€ì¤‘ì¹˜
        }

        print("ğŸ” ì‹œê³„ì—´ ê²€ì¦ ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print(f"   Purged K-Fold: {self.kfold_config['n_splits']}ê°œ fold")
        print(f"   í¼ì§€ ë¹„ìœ¨: {self.kfold_config['purge_pct']*100}%")
        print(f"   ì— ë°”ê³  ë°°ìˆ˜: {self.kfold_config['embargo_multiplier']}Ã—")

    def estimate_average_holding_period(self, sample_trades: List[Dict]) -> int:
        """í‰ê·  ë³´ìœ  ê¸°ê°„ ì¶”ì • (ë°” ë‹¨ìœ„)"""
        if not sample_trades:
            return 4  # ê¸°ë³¸ê°’: 4ë°” (1ì‹œê°„)

        holding_periods = []
        for trade in sample_trades:
            if "bars_held" in trade:
                holding_periods.append(trade["bars_held"])
            elif "entry_time" in trade and "exit_time" in trade:
                # ì‹œê°„ ì°¨ì´ë¡œ ê³„ì‚° (15ë¶„ë´‰ ê¸°ì¤€)
                entry_time = pd.to_datetime(trade["entry_time"])
                exit_time = pd.to_datetime(trade["exit_time"])
                time_diff = (exit_time - entry_time).total_seconds() / 900  # 15ë¶„ = 900ì´ˆ
                holding_periods.append(max(1, int(time_diff)))

        if holding_periods:
            avg_holding = int(np.mean(holding_periods))
            print(f"ğŸ“Š í‰ê·  ë³´ìœ  ê¸°ê°„: {avg_holding}ë°” ({avg_holding*15}ë¶„)")
            return max(2, avg_holding)  # ìµœì†Œ 2ë°”
        else:
            return 4  # ê¸°ë³¸ê°’

    def create_purged_kfold_splits(self, data_length: int, avg_holding_period: int) -> List[Tuple[np.ndarray, np.ndarray]]:
        """Purged K-Fold ë¶„í•  ìƒì„±"""
        n_splits = self.kfold_config["n_splits"]
        test_size = self.kfold_config["test_size"]
        purge_pct = self.kfold_config["purge_pct"]
        embargo_bars = avg_holding_period * self.kfold_config["embargo_multiplier"]

        print(f"ğŸ”„ Purged K-Fold ë¶„í•  ìƒì„±:")
        print(f"   ë°ì´í„° ê¸¸ì´: {data_length}")
        print(f"   ì— ë°”ê³ : {embargo_bars}ë°”")

        splits = []

        # ê° foldì˜ í…ŒìŠ¤íŠ¸ êµ¬ê°„ í¬ê¸°
        test_size_bars = int(data_length * test_size / n_splits)

        for fold in range(n_splits):
            # í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì •ì˜
            test_start = fold * test_size_bars
            test_end = min(test_start + test_size_bars, data_length)

            # í¼ì§€ êµ¬ê°„ ê³„ì‚°
            purge_bars = max(1, int(data_length * purge_pct))

            # í›ˆë ¨ êµ¬ê°„ ì •ì˜ (í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì œì™¸ + í¼ì§€ + ì— ë°”ê³ )
            train_indices = []

            # í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì´ì „ ë°ì´í„°
            if test_start > purge_bars + embargo_bars:
                train_start_1 = 0
                train_end_1 = test_start - purge_bars - embargo_bars
                train_indices.extend(range(train_start_1, train_end_1))

            # í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì´í›„ ë°ì´í„°
            if test_end + purge_bars + embargo_bars < data_length:
                train_start_2 = test_end + purge_bars + embargo_bars
                train_end_2 = data_length
                train_indices.extend(range(train_start_2, train_end_2))

            # ì¸ë±ìŠ¤ ë°°ì—´ ìƒì„±
            train_idx = np.array(train_indices)
            test_idx = np.array(range(test_start, test_end))

            # ìœ íš¨ì„± ê²€ì‚¬
            if len(train_idx) > 0 and len(test_idx) > 0:
                splits.append((train_idx, test_idx))

                print(f"   Fold {fold+1}: Train {len(train_idx)}, Test {len(test_idx)}")
                print(
                    f"     Train: {train_idx[0] if len(train_idx) > 0 else 'N/A'}-{train_idx[-1] if len(train_idx) > 0 else 'N/A'}"
                )
                print(f"     Test: {test_idx[0]}-{test_idx[-1]}")
            else:
                print(f"   Fold {fold+1}: ìŠ¤í‚µ (ë°ì´í„° ë¶€ì¡±)")

        return splits

    def validate_no_data_leakage(self, train_idx: np.ndarray, test_idx: np.ndarray, embargo_bars: int) -> bool:
        """ë°ì´í„° ëˆ„ìˆ˜ ê²€ì¦"""
        if len(train_idx) == 0 or len(test_idx) == 0:
            return False

        # í…ŒìŠ¤íŠ¸ êµ¬ê°„
        test_min = test_idx.min()
        test_max = test_idx.max()

        # í›ˆë ¨ ë°ì´í„°ê°€ í…ŒìŠ¤íŠ¸ êµ¬ê°„ê³¼ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
        for train_point in train_idx:
            # í…ŒìŠ¤íŠ¸ êµ¬ê°„ê³¼ ê²¹ì¹¨
            if test_min <= train_point <= test_max:
                return False

            # ì— ë°”ê³  êµ¬ê°„ ì¹¨ë²” (í…ŒìŠ¤íŠ¸ êµ¬ê°„ ì „í›„ embargo_bars ë²”ìœ„)
            if (test_min - embargo_bars <= train_point < test_min) or (test_max < train_point <= test_max + embargo_bars):
                return False

        return True

    def run_fold_validation(
        self, params: Dict, train_idx: np.ndarray, test_idx: np.ndarray, fold_id: int, strategy_func: Callable
    ) -> Optional[FoldResult]:
        """ë‹¨ì¼ fold ê²€ì¦ ì‹¤í–‰"""
        try:
            # ë°ì´í„° ëˆ„ìˆ˜ ê²€ì¦
            embargo_bars = self.estimate_average_holding_period([]) * self.kfold_config["embargo_multiplier"]
            if not self.validate_no_data_leakage(train_idx, test_idx, embargo_bars):
                print(f"âŒ Fold {fold_id}: ë°ì´í„° ëˆ„ìˆ˜ ê°ì§€")
                return None

            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì „ëµ ì‹¤í–‰ (ì‹œë®¬ë ˆì´ì…˜)
            test_metrics = self._simulate_fold_strategy(params, len(test_idx), fold_id)

            # ìµœì†Œ ê±°ë˜ ìˆ˜ í™•ì¸
            if test_metrics.total_trades < self.validation_config["min_test_trades"]:
                print(f"âš ï¸ Fold {fold_id}: ê±°ë˜ ìˆ˜ ë¶€ì¡± ({test_metrics.total_trades})")
                return None

            # ì ìˆ˜ ê³„ì‚°
            base_score = self.performance_evaluator.calculate_score(test_metrics)

            # DD íŒ¨ë„í‹° ì ìš©
            dd_penalty = max(0, test_metrics.max_drawdown - 0.15) * 10  # 15% ì´ˆê³¼ì‹œ íŒ¨ë„í‹°
            final_score = base_score - dd_penalty

            return FoldResult(
                fold_id=fold_id,
                train_start=train_idx[0] if len(train_idx) > 0 else 0,
                train_end=train_idx[-1] if len(train_idx) > 0 else 0,
                test_start=test_idx[0],
                test_end=test_idx[-1],
                metrics=test_metrics,
                score=final_score,
                params=params,
            )

        except Exception as e:
            print(f"âŒ Fold {fold_id} ê²€ì¦ ì‹¤íŒ¨: {e}")
            return None

    def _simulate_fold_strategy(self, params: Dict, test_length: int, fold_id: int) -> PerformanceMetrics:
        """Fold ì „ëµ ì‹œë®¬ë ˆì´ì…˜"""
        # ì‹œë“œ ì„¤ì • (foldë³„ë¡œ ë‹¤ë¥¸ ì‹œë“œ)
        np.random.seed(hash(str(params)) % 1000 + fold_id * 100)

        # ê±°ë˜ ìˆ˜ (í…ŒìŠ¤íŠ¸ ê¸¸ì´ì— ë¹„ë¡€)
        base_trades = max(20, int(test_length / 100))  # 100ë°”ë‹¹ 1ê±°ë˜
        total_trades = base_trades + np.random.randint(-5, 5)

        # íŒŒë¼ë¯¸í„° ì˜í–¥ (foldë³„ ë³€ë™ì„± ì¶”ê°€)
        target_r = params.get("target_r", 2.0)
        stop_mult = params.get("stop_atr_mult", 0.1)

        # Foldë³„ ì‹œì¥ ì¡°ê±´ ì‹œë®¬ë ˆì´ì…˜
        market_condition = np.random.choice(["bull", "bear", "sideways"], p=[0.3, 0.3, 0.4])

        if market_condition == "bull":
            win_rate_adj = 0.05  # ìƒìŠ¹ì¥ì—ì„œ ìŠ¹ë¥  ì¦ê°€
            volatility_adj = 0.8  # ë³€ë™ì„± ê°ì†Œ
        elif market_condition == "bear":
            win_rate_adj = -0.03  # í•˜ë½ì¥ì—ì„œ ìŠ¹ë¥  ê°ì†Œ
            volatility_adj = 1.2  # ë³€ë™ì„± ì¦ê°€
        else:  # sideways
            win_rate_adj = 0.0
            volatility_adj = 1.0

        # ìŠ¹ë¥  ê³„ì‚°
        base_win_rate = 0.55 - (target_r - 2.0) * 0.02
        win_rate = max(0.35, min(0.75, base_win_rate + win_rate_adj + np.random.normal(0, 0.03)))

        # í‰ê·  ì†ìµ
        avg_win = target_r * 50 * (1 + np.random.normal(0, 0.1))
        avg_loss = -50 * (1 + np.random.normal(0, 0.1))

        # ë³€ë™ì„± (ì‹œì¥ ì¡°ê±´ ë°˜ì˜)
        win_volatility = abs(avg_win) * 0.2 * volatility_adj
        loss_volatility = abs(avg_loss) * 0.2 * volatility_adj

        # PnL ìƒì„±
        pnl_data = []
        for _ in range(total_trades):
            if np.random.random() < win_rate:
                pnl = np.random.normal(avg_win, win_volatility)
            else:
                pnl = np.random.normal(avg_loss, loss_volatility)
            pnl_data.append(pnl)

        # DataFrame ìƒì„±
        trades_df = pd.DataFrame({"pnl": pnl_data})

        # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
        metrics = self.performance_evaluator.calculate_metrics(trades_df)

        return metrics

    def calculate_cross_validation_score(self, fold_results: List[FoldResult]) -> Tuple[float, Dict]:
        """êµì°¨ ê²€ì¦ ì ìˆ˜ ê³„ì‚°"""
        if not fold_results:
            return -10000, {}

        # ê° foldì˜ ì ìˆ˜ ìˆ˜ì§‘
        scores = [result.score for result in fold_results]
        metrics_list = [result.metrics for result in fold_results]

        # ë©”ë””ì•ˆ ì ìˆ˜
        median_score = np.median(scores)

        # ì¼ê´€ì„± í™•ì¸ (ìˆ˜ìµì„± ìˆëŠ” fold ë¹„ìœ¨)
        profitable_folds = sum(1 for result in fold_results if result.metrics.total_return > 0)
        consistency_ratio = profitable_folds / len(fold_results)

        # ì•ˆì •ì„± ê³„ì‚° (ì ìˆ˜ì˜ IQR)
        q75, q25 = np.percentile(scores, [75, 25])
        iqr = q75 - q25
        stability_penalty = iqr * self.validation_config["stability_weight"]

        # ìµœì¢… ì ìˆ˜
        final_score = median_score - stability_penalty

        # ì¼ê´€ì„± íŒ¨ë„í‹°
        if consistency_ratio < self.validation_config["consistency_threshold"]:
            consistency_penalty = (self.validation_config["consistency_threshold"] - consistency_ratio) * 1000
            final_score -= consistency_penalty

        # í†µê³„ ì •ë³´
        stats = {
            "median_score": median_score,
            "score_std": np.std(scores),
            "score_iqr": iqr,
            "consistency_ratio": consistency_ratio,
            "profitable_folds": profitable_folds,
            "total_folds": len(fold_results),
            "stability_penalty": stability_penalty,
            "final_score": final_score,
        }

        return final_score, stats

    def run_timeseries_validation(
        self, candidates: List[Tuple[Dict, float, PerformanceMetrics]], strategy_func: Callable, data_length: int = 50000
    ) -> List[Tuple[Dict, float, Dict]]:
        """ì‹œê³„ì—´ ê²€ì¦ ì‹¤í–‰"""
        print(f"\nğŸ” ì‹œê³„ì—´ ê²€ì¦ ì‹œì‘ ({len(candidates)}ê°œ í›„ë³´)")

        # í‰ê·  ë³´ìœ  ê¸°ê°„ ì¶”ì • (ìƒ˜í”Œ ë°ì´í„° ê¸°ë°˜)
        avg_holding_period = self.estimate_average_holding_period([])

        # Purged K-Fold ë¶„í•  ìƒì„±
        splits = self.create_purged_kfold_splits(data_length, avg_holding_period)

        if len(splits) == 0:
            print("âŒ ìœ íš¨í•œ foldê°€ ì—†ìŠµë‹ˆë‹¤")
            return []

        validated_candidates = []

        for i, (params, original_score, original_metrics) in enumerate(candidates):
            print(f"\nğŸ“Š í›„ë³´ {i+1}/{len(candidates)} ê²€ì¦ ì¤‘...")

            fold_results = []

            # ê° foldì—ì„œ ê²€ì¦
            for fold_id, (train_idx, test_idx) in enumerate(splits):
                fold_result = self.run_fold_validation(params, train_idx, test_idx, fold_id + 1, strategy_func)

                if fold_result:
                    fold_results.append(fold_result)
                    print(
                        f"   Fold {fold_id+1}: Score {fold_result.score:.4f}, "
                        f"PF {fold_result.metrics.profit_factor:.2f}, "
                        f"ê±°ë˜ {fold_result.metrics.total_trades}ê°œ"
                    )

            # êµì°¨ ê²€ì¦ ì ìˆ˜ ê³„ì‚°
            if len(fold_results) >= 3:  # ìµœì†Œ 3ê°œ fold í•„ìš”
                cv_score, stats = self.calculate_cross_validation_score(fold_results)

                validated_candidates.append((params, cv_score, stats))

                print(f"   CV ì ìˆ˜: {cv_score:.4f} (ë©”ë””ì•ˆ: {stats['median_score']:.4f})")
                print(f"   ì¼ê´€ì„±: {stats['consistency_ratio']:.1%} ({stats['profitable_folds']}/{stats['total_folds']})")
            else:
                print(f"   âŒ ìœ íš¨í•œ fold ë¶€ì¡± ({len(fold_results)}/5)")

        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        validated_candidates.sort(key=lambda x: x[1], reverse=True)

        # Top-3 ì„ ë³„
        top_3 = validated_candidates[:3]

        print(f"\nâœ… ì‹œê³„ì—´ ê²€ì¦ ì™„ë£Œ")
        print(f"   ê²€ì¦ëœ í›„ë³´: {len(validated_candidates)}ê°œ")
        print(f"   Top-3 ìŠ¹ê¸‰: {len(top_3)}ê°œ")

        return top_3

    def print_validation_results(self, results: List[Tuple[Dict, float, Dict]], title: str = "ì‹œê³„ì—´ ê²€ì¦ ê²°ê³¼"):
        """ê²€ì¦ ê²°ê³¼ ì¶œë ¥"""
        print(f"\nğŸ“Š {title}")
        print("=" * 80)

        for i, (params, cv_score, stats) in enumerate(results):
            print(f"\nğŸ† ìˆœìœ„ {i+1}: CV ì ìˆ˜ {cv_score:.4f}")
            print(f"   ë©”ë””ì•ˆ ì ìˆ˜: {stats['median_score']:.4f}")
            print(f"   ì ìˆ˜ í‘œì¤€í¸ì°¨: {stats['score_std']:.4f}")
            print(f"   ì¼ê´€ì„±: {stats['consistency_ratio']:.1%} ({stats['profitable_folds']}/{stats['total_folds']})")
            print(f"   ì•ˆì •ì„± íŒ¨ë„í‹°: {stats['stability_penalty']:.4f}")

            # ì£¼ìš” íŒŒë¼ë¯¸í„°
            key_params = ["target_r", "stop_atr_mult", "swing_len", "rr_percentile"]
            param_str = ", ".join(
                [
                    f"{k}: {params.get(k, 'N/A'):.3f}" if isinstance(params.get(k), float) else f"{k}: {params.get(k, 'N/A')}"
                    for k in key_params
                ]
            )
            print(f"   íŒŒë¼ë¯¸í„°: {param_str}")


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    # ë°ì´í„° ì—”ì§„ ì´ˆê¸°í™”
    data_engine = FastDataEngine()

    # ì„±ê³¼ í‰ê°€ì ì´ˆê¸°í™”
    performance_evaluator = PerformanceEvaluator()

    # ì‹œê³„ì—´ ê²€ì¦ì ì´ˆê¸°í™”
    validator = TimeSeriesValidator(data_engine, performance_evaluator)

    # ê°€ìƒì˜ í›„ë³´ë“¤
    test_candidates = [
        ({"target_r": 2.5, "stop_atr_mult": 0.1, "swing_len": 5, "rr_percentile": 0.2}, 0.8, None),
        ({"target_r": 3.0, "stop_atr_mult": 0.08, "swing_len": 4, "rr_percentile": 0.15}, 0.7, None),
        ({"target_r": 2.2, "stop_atr_mult": 0.12, "swing_len": 6, "rr_percentile": 0.25}, 0.6, None),
        ({"target_r": 2.8, "stop_atr_mult": 0.09, "swing_len": 3, "rr_percentile": 0.18}, 0.5, None),
        ({"target_r": 3.2, "stop_atr_mult": 0.07, "swing_len": 7, "rr_percentile": 0.22}, 0.4, None),
    ]

    # ê°€ìƒì˜ ì „ëµ í•¨ìˆ˜
    def dummy_strategy_func(params):
        return params

    # ì‹œê³„ì—´ ê²€ì¦ ì‹¤í–‰
    results = validator.run_timeseries_validation(test_candidates, dummy_strategy_func)

    # ê²°ê³¼ ì¶œë ¥
    validator.print_validation_results(results)


if __name__ == "__main__":
    main()
