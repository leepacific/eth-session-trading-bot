#!/usr/bin/env python3
"""
ì„±ëŠ¥ ìµœì í™” ë° ë°°í¬ ì¤€ë¹„ êµ¬í˜„
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” ë° ìºì‹œ ê´€ë¦¬
- ë³‘ë ¬ ì²˜ë¦¬ ì„±ëŠ¥ íŠœë‹
- ê²°ê³¼ ì €ì¥ ë° íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- Railway ë°°í¬ í™˜ê²½ ì„¤ì • ë° í…ŒìŠ¤íŠ¸
"""

import os
import gc
import psutil
import threading
import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
import numpy as np
import pandas as pd
import pickle
import json
import sqlite3
import warnings
warnings.filterwarnings('ignore')

@dataclass
class PerformanceConfig:
    """ì„±ëŠ¥ ìµœì í™” ì„¤ì •"""
    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    max_memory_usage_gb: float = 4.0         # ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    cache_size_mb: float = 512.0             # ìºì‹œ í¬ê¸°
    gc_threshold: float = 0.8                # GC ì‹¤í–‰ ì„ê³„ê°’
    
    # ë³‘ë ¬ ì²˜ë¦¬
    max_workers: int = mp.cpu_count()        # ìµœëŒ€ ì›Œì»¤ ìˆ˜
    chunk_size: int = 1000                   # ì²­í¬ í¬ê¸°
    use_process_pool: bool = True            # í”„ë¡œì„¸ìŠ¤ í’€ ì‚¬ìš©
    
    # ìºì‹œ ê´€ë¦¬
    cache_ttl_hours: int = 24                # ìºì‹œ TTL
    auto_cleanup: bool = True                # ìë™ ì •ë¦¬
    
    # ë°°í¬ ì„¤ì •
    railway_port: int = 8000                 # Railway í¬íŠ¸
    health_check_interval: int = 30          # í—¬ìŠ¤ì²´í¬ ê°„ê²©
    log_level: str = "INFO"                  # ë¡œê·¸ ë ˆë²¨

@dataclass
class MemoryStats:
    """ë©”ëª¨ë¦¬ í†µê³„"""
    total_gb: float
    available_gb: float
    used_gb: float
    usage_percent: float
    process_memory_gb: float

@dataclass
class PerformanceMetrics:
    """ì„±ëŠ¥ ì§€í‘œ"""
    timestamp: datetime
    memory_stats: MemoryStats
    cpu_percent: float
    active_threads: int
    cache_hit_rate: float
    processing_speed: float  # items/second

class MemoryManager:
    def __init__(self, config: PerformanceConfig):
        """ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™”"""
        self.config = config
        self.cache: Dict[str, Any] = {}
        self.cache_timestamps: Dict[str, datetime] = {}
        self.cache_lock = threading.Lock()
        
        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
        self.memory_stats_history: List[MemoryStats] = []
        self.monitoring_active = False
        self.monitor_thread: Optional[threading.Thread] = None
        
        print("ğŸ§  ë©”ëª¨ë¦¬ ê´€ë¦¬ì ì´ˆê¸°í™”")
        print(f"   ìµœëŒ€ ë©”ëª¨ë¦¬: {self.config.max_memory_usage_gb}GB")
        print(f"   ìºì‹œ í¬ê¸°: {self.config.cache_size_mb}MB")
    
    def start_monitoring(self):
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.monitoring_active = True
        self.monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitor_thread.start()
        print("ğŸ“Š ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘")
    
    def stop_monitoring(self):
        """ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring_active = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5.0)
        print("â¹ï¸ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def _monitoring_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.monitoring_active:
            try:
                stats = self.get_memory_stats()
                self.memory_stats_history.append(stats)
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì„ê³„ê°’ ì´ˆê³¼ì‹œ ì •ë¦¬
                if stats.usage_percent > self.config.gc_threshold * 100:
                    self.cleanup_memory()
                
                # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ (ìµœê·¼ 1000ê°œë§Œ)
                if len(self.memory_stats_history) > 1000:
                    self.memory_stats_history = self.memory_stats_history[-1000:]
                
                threading.Event().wait(10.0)  # 10ì´ˆ ê°„ê²©
                
            except Exception as e:
                print(f"ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
                threading.Event().wait(5.0)
    
    def get_memory_stats(self) -> MemoryStats:
        """ë©”ëª¨ë¦¬ í†µê³„ ì¡°íšŒ"""
        memory = psutil.virtual_memory()
        process = psutil.Process()
        
        return MemoryStats(
            total_gb=memory.total / (1024**3),
            available_gb=memory.available / (1024**3),
            used_gb=memory.used / (1024**3),
            usage_percent=memory.percent,
            process_memory_gb=process.memory_info().rss / (1024**3)
        )
    
    def cache_get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        with self.cache_lock:
            if key in self.cache:
                # TTL ì²´í¬
                if self._is_cache_valid(key):
                    return self.cache[key]
                else:
                    # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                    del self.cache[key]
                    del self.cache_timestamps[key]
        
        return None
    
    def cache_set(self, key: str, value: Any):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        with self.cache_lock:
            # ìºì‹œ í¬ê¸° ì²´í¬
            if self._get_cache_size_mb() > self.config.cache_size_mb:
                self._evict_old_cache()
            
            self.cache[key] = value
            self.cache_timestamps[key] = datetime.now()
    
    def _is_cache_valid(self, key: str) -> bool:
        """ìºì‹œ ìœ íš¨ì„± ì²´í¬"""
        if key not in self.cache_timestamps:
            return False
        
        age = datetime.now() - self.cache_timestamps[key]
        return age.total_seconds() < self.config.cache_ttl_hours * 3600
    
    def _get_cache_size_mb(self) -> float:
        """ìºì‹œ í¬ê¸° ê³„ì‚° (MB)"""
        total_size = 0
        for value in self.cache.values():
            try:
                if isinstance(value, (pd.DataFrame, np.ndarray)):
                    total_size += value.nbytes
                else:
                    total_size += len(pickle.dumps(value))
            except:
                total_size += 1024  # ê¸°ë³¸ê°’
        
        return total_size / (1024**2)
    
    def _evict_old_cache(self):
        """ì˜¤ë˜ëœ ìºì‹œ ì œê±°"""
        # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª©ë¶€í„° ì œê±°
        if not self.cache_timestamps:
            return
        
        oldest_key = min(self.cache_timestamps.keys(), 
                        key=lambda k: self.cache_timestamps[k])
        
        del self.cache[oldest_key]
        del self.cache_timestamps[oldest_key]
        
        print(f"ğŸ—‘ï¸ ìºì‹œ ì œê±°: {oldest_key}")
    
    def cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬"""
        print("ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘...")
        
        # ìºì‹œ ì •ë¦¬
        with self.cache_lock:
            expired_keys = []
            for key in self.cache_timestamps:
                if not self._is_cache_valid(key):
                    expired_keys.append(key)
            
            for key in expired_keys:
                del self.cache[key]
                del self.cache_timestamps[key]
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
        collected = gc.collect()
        
        print(f"   ë§Œë£Œëœ ìºì‹œ: {len(expired_keys)}ê°œ ì œê±°")
        print(f"   ê°€ë¹„ì§€ ì»¬ë ‰ì…˜: {collected}ê°œ ê°ì²´ ì •ë¦¬")
    
    def get_cache_stats(self) -> Dict:
        """ìºì‹œ í†µê³„"""
        with self.cache_lock:
            return {
                'cache_entries': len(self.cache),
                'cache_size_mb': self._get_cache_size_mb(),
                'hit_rate': getattr(self, '_hit_count', 0) / max(getattr(self, '_access_count', 1), 1),
                'oldest_entry': min(self.cache_timestamps.values()) if self.cache_timestamps else None
            }

class ParallelProcessor:
    def __init__(self, config: PerformanceConfig):
        """ë³‘ë ¬ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”"""
        self.config = config
        self.thread_pool: Optional[ThreadPoolExecutor] = None
        self.process_pool: Optional[ProcessPoolExecutor] = None
        
        print("âš¡ ë³‘ë ¬ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”")
        print(f"   ìµœëŒ€ ì›Œì»¤: {self.config.max_workers}ê°œ")
        print(f"   ì²­í¬ í¬ê¸°: {self.config.chunk_size}")
        print(f"   í”„ë¡œì„¸ìŠ¤ í’€: {'ì‚¬ìš©' if self.config.use_process_pool else 'ë¯¸ì‚¬ìš©'}")
    
    def start_pools(self):
        """í’€ ì‹œì‘"""
        # ìŠ¤ë ˆë“œ í’€ (I/O ì§‘ì•½ì  ì‘ì—…ìš©)
        self.thread_pool = ThreadPoolExecutor(
            max_workers=min(self.config.max_workers, 32),
            thread_name_prefix="opt_thread"
        )
        
        # í”„ë¡œì„¸ìŠ¤ í’€ (CPU ì§‘ì•½ì  ì‘ì—…ìš©)
        if self.config.use_process_pool:
            self.process_pool = ProcessPoolExecutor(
                max_workers=min(self.config.max_workers, mp.cpu_count()),
                mp_context=mp.get_context('spawn')
            )
        
        print("ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ í’€ ì‹œì‘")
    
    def stop_pools(self):
        """í’€ ì¤‘ì§€"""
        if self.thread_pool:
            self.thread_pool.shutdown(wait=True)
            self.thread_pool = None
        
        if self.process_pool:
            self.process_pool.shutdown(wait=True)
            self.process_pool = None
        
        print("â¹ï¸ ë³‘ë ¬ ì²˜ë¦¬ í’€ ì¤‘ì§€")
    
    def process_parallel(self, func: Callable, data: List[Any], 
                        use_processes: bool = False) -> List[Any]:
        """ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰"""
        if not data:
            return []
        
        # ì²­í¬ ë¶„í• 
        chunks = [data[i:i + self.config.chunk_size] 
                 for i in range(0, len(data), self.config.chunk_size)]
        
        executor = self.process_pool if (use_processes and self.process_pool) else self.thread_pool
        
        if not executor:
            # í’€ì´ ì—†ìœ¼ë©´ ìˆœì°¨ ì²˜ë¦¬
            return [func(item) for item in data]
        
        # ë³‘ë ¬ ì‹¤í–‰
        futures = []
        for chunk in chunks:
            future = executor.submit(self._process_chunk, func, chunk)
            futures.append(future)
        
        # ê²°ê³¼ ìˆ˜ì§‘
        results = []
        for future in futures:
            try:
                chunk_results = future.result(timeout=300)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
                results.extend(chunk_results)
            except Exception as e:
                print(f"ë³‘ë ¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                # ì‹¤íŒ¨í•œ ì²­í¬ëŠ” ìˆœì°¨ ì²˜ë¦¬ë¡œ ëŒ€ì²´
                results.extend([None] * self.config.chunk_size)
        
        return results[:len(data)]  # ì›ë˜ í¬ê¸°ë¡œ ë§ì¶¤
    
    @staticmethod
    def _process_chunk(func: Callable, chunk: List[Any]) -> List[Any]:
        """ì²­í¬ ì²˜ë¦¬"""
        return [func(item) for item in chunk]
    
    def get_performance_stats(self) -> Dict:
        """ì„±ëŠ¥ í†µê³„"""
        stats = {
            'thread_pool_active': self.thread_pool is not None,
            'process_pool_active': self.process_pool is not None,
            'cpu_count': mp.cpu_count(),
            'active_threads': threading.active_count()
        }
        
        if self.thread_pool:
            stats['thread_pool_size'] = self.thread_pool._max_workers
        
        if self.process_pool:
            stats['process_pool_size'] = self.process_pool._max_workers
        
        return stats

class ResultManager:
    def __init__(self, config: PerformanceConfig, db_path: str = "optimization_results.db"):
        """ê²°ê³¼ ê´€ë¦¬ì ì´ˆê¸°í™”"""
        self.config = config
        self.db_path = db_path
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self._init_database()
        
        print("ğŸ’¾ ê²°ê³¼ ê´€ë¦¬ì ì´ˆê¸°í™”")
        print(f"   ë°ì´í„°ë² ì´ìŠ¤: {self.db_path}")
    
    def _init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ìµœì í™” ê²°ê³¼ í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS optimization_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    pipeline_id TEXT UNIQUE NOT NULL,
                    symbol TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    start_time TIMESTAMP NOT NULL,
                    end_time TIMESTAMP,
                    status TEXT NOT NULL,
                    parameters TEXT,
                    metrics TEXT,
                    duration_seconds REAL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ì„±ëŠ¥ ì§€í‘œ í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS performance_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    pipeline_id TEXT NOT NULL,
                    timestamp TIMESTAMP NOT NULL,
                    memory_usage_gb REAL,
                    cpu_percent REAL,
                    cache_hit_rate REAL,
                    processing_speed REAL,
                    FOREIGN KEY (pipeline_id) REFERENCES optimization_results (pipeline_id)
                )
            ''')
            
            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_pipeline_id ON optimization_results (pipeline_id)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON performance_metrics (timestamp)')
            
            conn.commit()
    
    def save_result(self, pipeline_id: str, symbol: str, timeframe: str,
                   start_time: datetime, end_time: datetime, status: str,
                   parameters: Dict, metrics: Dict, duration_seconds: float):
        """ê²°ê³¼ ì €ì¥"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT OR REPLACE INTO optimization_results 
                (pipeline_id, symbol, timeframe, start_time, end_time, status, 
                 parameters, metrics, duration_seconds)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                pipeline_id, symbol, timeframe, start_time, end_time, status,
                json.dumps(parameters), json.dumps(metrics), duration_seconds
            ))
            
            conn.commit()
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {pipeline_id}")
    
    def save_performance_metric(self, pipeline_id: str, metric: PerformanceMetrics):
        """ì„±ëŠ¥ ì§€í‘œ ì €ì¥"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO performance_metrics 
                (pipeline_id, timestamp, memory_usage_gb, cpu_percent, 
                 cache_hit_rate, processing_speed)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                pipeline_id, metric.timestamp, metric.memory_stats.process_memory_gb,
                metric.cpu_percent, metric.cache_hit_rate, metric.processing_speed
            ))
            
            conn.commit()
    
    def get_results(self, limit: int = 100) -> pd.DataFrame:
        """ê²°ê³¼ ì¡°íšŒ"""
        with sqlite3.connect(self.db_path) as conn:
            query = '''
                SELECT * FROM optimization_results 
                ORDER BY created_at DESC 
                LIMIT ?
            '''
            return pd.read_sql_query(query, conn, params=(limit,))
    
    def get_performance_history(self, pipeline_id: str) -> pd.DataFrame:
        """ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        with sqlite3.connect(self.db_path) as conn:
            query = '''
                SELECT * FROM performance_metrics 
                WHERE pipeline_id = ?
                ORDER BY timestamp
            '''
            return pd.read_sql_query(query, conn, params=(pipeline_id,))
    
    def cleanup_old_results(self, days: int = 30):
        """ì˜¤ë˜ëœ ê²°ê³¼ ì •ë¦¬"""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ ì„±ëŠ¥ ì§€í‘œ ì‚­ì œ
            cursor.execute('''
                DELETE FROM performance_metrics 
                WHERE timestamp < ?
            ''', (cutoff_date,))
            
            # ì˜¤ë˜ëœ ìµœì í™” ê²°ê³¼ ì‚­ì œ
            cursor.execute('''
                DELETE FROM optimization_results 
                WHERE created_at < ?
            ''', (cutoff_date,))
            
            deleted_count = cursor.rowcount
            conn.commit()
        
        print(f"ğŸ—‘ï¸ ì˜¤ë˜ëœ ê²°ê³¼ ì •ë¦¬: {deleted_count}ê°œ ì‚­ì œ")

class DeploymentManager:
    def __init__(self, config: PerformanceConfig):
        """ë°°í¬ ê´€ë¦¬ì ì´ˆê¸°í™”"""
        self.config = config
        
        print("ğŸš€ ë°°í¬ ê´€ë¦¬ì ì´ˆê¸°í™”")
        print(f"   Railway í¬íŠ¸: {self.config.railway_port}")
    
    def create_railway_config(self) -> Dict:
        """Railway ë°°í¬ ì„¤ì • ìƒì„±"""
        config = {
            "build": {
                "builder": "NIXPACKS"
            },
            "deploy": {
                "startCommand": "python main.py",
                "healthcheckPath": "/health",
                "healthcheckTimeout": 300,
                "restartPolicyType": "ON_FAILURE",
                "restartPolicyMaxRetries": 3
            },
            "environments": {
                "production": {
                    "variables": {
                        "PORT": str(self.config.railway_port),
                        "LOG_LEVEL": self.config.log_level,
                        "PYTHONUNBUFFERED": "1",
                        "MKL_NUM_THREADS": "1"
                    }
                }
            }
        }
        
        return config
    
    def create_dockerfile(self) -> str:
        """Dockerfile ìƒì„±"""
        dockerfile_content = f'''
FROM python:3.11-slim

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
RUN apt-get update && apt-get install -y \\
    gcc \\
    g++ \\
    && rm -rf /var/lib/apt/lists/*

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# ì˜ì¡´ì„± íŒŒì¼ ë³µì‚¬
COPY requirements.txt .

# Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE {self.config.railway_port}

# í—¬ìŠ¤ì²´í¬
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\
    CMD python -c "import requests; requests.get('http://localhost:{self.config.railway_port}/health')"

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
CMD ["python", "main.py"]
'''
        return dockerfile_content
    
    def create_requirements_txt(self) -> str:
        """requirements.txt ìƒì„±"""
        requirements = [
            "numpy>=1.21.0",
            "pandas>=1.3.0",
            "scipy>=1.7.0",
            "scikit-learn>=1.0.0",
            "numba>=0.56.0",
            "psutil>=5.8.0",
            "fastapi>=0.68.0",
            "uvicorn>=0.15.0",
            "pydantic>=1.8.0",
            "python-multipart>=0.0.5"
        ]
        
        return "\n".join(requirements)
    
    def create_health_check_endpoint(self) -> str:
        """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ìƒì„±"""
        health_check_code = '''
from fastapi import FastAPI, HTTPException
from datetime import datetime
import psutil
import os

app = FastAPI(title="Optimization Pipeline API")

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì²´í¬
        memory = psutil.virtual_memory()
        cpu_percent = psutil.cpu_percent(interval=1)
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ 90% ì´ìƒì´ë©´ ê²½ê³ 
        if memory.percent > 90:
            raise HTTPException(status_code=503, detail="High memory usage")
        
        # CPU ì‚¬ìš©ëŸ‰ì´ 95% ì´ìƒì´ë©´ ê²½ê³ 
        if cpu_percent > 95:
            raise HTTPException(status_code=503, detail="High CPU usage")
        
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "memory_percent": memory.percent,
            "cpu_percent": cpu_percent,
            "available_memory_gb": memory.available / (1024**3)
        }
    
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Health check failed: {str(e)}")

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {"message": "Optimization Pipeline API", "version": "1.0.0"}

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
'''
        return health_check_code
    
    def run_deployment_tests(self) -> Dict:
        """ë°°í¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ§ª ë°°í¬ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        test_results = {}
        
        # 1. ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸
        try:
            memory = psutil.virtual_memory()
            test_results['memory_test'] = {
                'passed': memory.available > 1024**3,  # 1GB ì´ìƒ
                'available_gb': memory.available / (1024**3),
                'message': 'OK' if memory.available > 1024**3 else 'Insufficient memory'
            }
        except Exception as e:
            test_results['memory_test'] = {'passed': False, 'error': str(e)}
        
        # 2. CPU í…ŒìŠ¤íŠ¸
        try:
            cpu_count = psutil.cpu_count()
            test_results['cpu_test'] = {
                'passed': cpu_count >= 1,
                'cpu_count': cpu_count,
                'message': 'OK' if cpu_count >= 1 else 'No CPU available'
            }
        except Exception as e:
            test_results['cpu_test'] = {'passed': False, 'error': str(e)}
        
        # 3. ë””ìŠ¤í¬ í…ŒìŠ¤íŠ¸
        try:
            disk = psutil.disk_usage('/')
            test_results['disk_test'] = {
                'passed': disk.free > 1024**3,  # 1GB ì´ìƒ
                'free_gb': disk.free / (1024**3),
                'message': 'OK' if disk.free > 1024**3 else 'Insufficient disk space'
            }
        except Exception as e:
            test_results['disk_test'] = {'passed': False, 'error': str(e)}
        
        # 4. ë„¤íŠ¸ì›Œí¬ í…ŒìŠ¤íŠ¸
        try:
            import socket
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)
            result = sock.connect_ex(('8.8.8.8', 53))
            sock.close()
            
            test_results['network_test'] = {
                'passed': result == 0,
                'message': 'OK' if result == 0 else 'Network connectivity issue'
            }
        except Exception as e:
            test_results['network_test'] = {'passed': False, 'error': str(e)}
        
        # ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼
        all_passed = all(test.get('passed', False) for test in test_results.values())
        test_results['overall'] = {
            'passed': all_passed,
            'message': 'All tests passed' if all_passed else 'Some tests failed'
        }
        
        print(f"   í…ŒìŠ¤íŠ¸ ê²°ê³¼: {'âœ… í†µê³¼' if all_passed else 'âŒ ì‹¤íŒ¨'}")
        
        return test_results

class PerformanceOptimizer:
    def __init__(self, config: PerformanceConfig = None):
        """ì„±ëŠ¥ ìµœì í™”ê¸° ì´ˆê¸°í™”"""
        self.config = config or PerformanceConfig()
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.memory_manager = MemoryManager(self.config)
        self.parallel_processor = ParallelProcessor(self.config)
        self.result_manager = ResultManager(self.config)
        self.deployment_manager = DeploymentManager(self.config)
        
        # ì„±ëŠ¥ ì§€í‘œ ì¶”ì 
        self.performance_history: List[PerformanceMetrics] = []
        
        print("âš¡ ì„±ëŠ¥ ìµœì í™”ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def start_optimization(self):
        """ìµœì í™” ì‹œì‘"""
        print("ğŸš€ ì„±ëŠ¥ ìµœì í™” ì‹œì‘...")
        
        # ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        self.memory_manager.start_monitoring()
        
        # ë³‘ë ¬ ì²˜ë¦¬ í’€ ì‹œì‘
        self.parallel_processor.start_pools()
        
        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        os.environ['OMP_NUM_THREADS'] = '1'
        os.environ['MKL_NUM_THREADS'] = '1'
        os.environ['NUMEXPR_NUM_THREADS'] = '1'
        
        print("âœ… ì„±ëŠ¥ ìµœì í™” í™œì„±í™”")
    
    def stop_optimization(self):
        """ìµœì í™” ì¤‘ì§€"""
        print("â¹ï¸ ì„±ëŠ¥ ìµœì í™” ì¤‘ì§€...")
        
        # ì»´í¬ë„ŒíŠ¸ ì¤‘ì§€
        self.memory_manager.stop_monitoring()
        self.parallel_processor.stop_pools()
        
        print("âœ… ì„±ëŠ¥ ìµœì í™” ë¹„í™œì„±í™”")
    
    def collect_performance_metrics(self, pipeline_id: str) -> PerformanceMetrics:
        """ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘"""
        memory_stats = self.memory_manager.get_memory_stats()
        cache_stats = self.memory_manager.get_cache_stats()
        
        metrics = PerformanceMetrics(
            timestamp=datetime.now(),
            memory_stats=memory_stats,
            cpu_percent=psutil.cpu_percent(interval=0.1),
            active_threads=threading.active_count(),
            cache_hit_rate=cache_stats['hit_rate'],
            processing_speed=0.0  # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì²˜ë¦¬ ì†ë„ ê³„ì‚°
        )
        
        # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.performance_history.append(metrics)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        self.result_manager.save_performance_metric(pipeline_id, metrics)
        
        return metrics
    
    def get_optimization_report(self) -> Dict:
        """ìµœì í™” ë³´ê³ ì„œ ìƒì„±"""
        if not self.performance_history:
            return {'error': 'No performance data available'}
        
        # ìµœê·¼ ì„±ëŠ¥ ì§€í‘œë“¤
        recent_metrics = self.performance_history[-10:]  # ìµœê·¼ 10ê°œ
        
        # í‰ê·  ê³„ì‚°
        avg_memory = np.mean([m.memory_stats.process_memory_gb for m in recent_metrics])
        avg_cpu = np.mean([m.cpu_percent for m in recent_metrics])
        avg_cache_hit = np.mean([m.cache_hit_rate for m in recent_metrics])
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì„¸
        memory_trend = "stable"
        if len(recent_metrics) >= 5:
            early_avg = np.mean([m.memory_stats.process_memory_gb for m in recent_metrics[:5]])
            late_avg = np.mean([m.memory_stats.process_memory_gb for m in recent_metrics[-5:]])
            
            if late_avg > early_avg * 1.1:
                memory_trend = "increasing"
            elif late_avg < early_avg * 0.9:
                memory_trend = "decreasing"
        
        return {
            'performance_summary': {
                'avg_memory_gb': avg_memory,
                'avg_cpu_percent': avg_cpu,
                'avg_cache_hit_rate': avg_cache_hit,
                'memory_trend': memory_trend
            },
            'cache_stats': self.memory_manager.get_cache_stats(),
            'parallel_stats': self.parallel_processor.get_performance_stats(),
            'recommendations': self._generate_recommendations(avg_memory, avg_cpu, avg_cache_hit)
        }
    
    def _generate_recommendations(self, avg_memory: float, avg_cpu: float, 
                                avg_cache_hit: float) -> List[str]:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if avg_memory > self.config.max_memory_usage_gb * 0.8:
            recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ìºì‹œ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ ë°ì´í„° ì²­í¬ í¬ê¸°ë¥¼ ì¡°ì •í•˜ì„¸ìš”.")
        
        if avg_cpu > 80:
            recommendations.append("CPU ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ë³‘ë ¬ ì›Œì»¤ ìˆ˜ë¥¼ ì¤„ì´ê±°ë‚˜ ì²˜ë¦¬ ê°„ê²©ì„ ëŠ˜ë¦¬ì„¸ìš”.")
        
        if avg_cache_hit < 0.7:
            recommendations.append("ìºì‹œ ì ì¤‘ë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. ìºì‹œ í¬ê¸°ë¥¼ ëŠ˜ë¦¬ê±°ë‚˜ TTLì„ ì¡°ì •í•˜ì„¸ìš”.")
        
        if not recommendations:
            recommendations.append("ì„±ëŠ¥ì´ ì–‘í˜¸í•©ë‹ˆë‹¤. í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")
        
        return recommendations
    
    def prepare_deployment(self, output_dir: str = "deployment"):
        """ë°°í¬ ì¤€ë¹„"""
        print(f"ğŸ“¦ ë°°í¬ íŒŒì¼ ì¤€ë¹„ ì¤‘... ({output_dir})")
        
        os.makedirs(output_dir, exist_ok=True)
        
        # Railway ì„¤ì • íŒŒì¼
        railway_config = self.deployment_manager.create_railway_config()
        with open(os.path.join(output_dir, "railway.json"), 'w') as f:
            json.dump(railway_config, f, indent=2)
        
        # Dockerfile
        dockerfile_content = self.deployment_manager.create_dockerfile()
        with open(os.path.join(output_dir, "Dockerfile"), 'w') as f:
            f.write(dockerfile_content)
        
        # requirements.txt
        requirements_content = self.deployment_manager.create_requirements_txt()
        with open(os.path.join(output_dir, "requirements.txt"), 'w') as f:
            f.write(requirements_content)
        
        # í—¬ìŠ¤ì²´í¬ API
        health_check_content = self.deployment_manager.create_health_check_endpoint()
        with open(os.path.join(output_dir, "main.py"), 'w') as f:
            f.write(health_check_content)
        
        print(f"âœ… ë°°í¬ íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ: {output_dir}")
        
        # ë°°í¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_results = self.deployment_manager.run_deployment_tests()
        
        return {
            'deployment_ready': test_results['overall']['passed'],
            'test_results': test_results,
            'output_directory': output_dir
        }

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ ì„±ëŠ¥ ìµœì í™” ë° ë°°í¬ ì¤€ë¹„ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    # ì„±ëŠ¥ ìµœì í™”ê¸° ì´ˆê¸°í™”
    config = PerformanceConfig(
        max_memory_usage_gb=2.0,  # í…ŒìŠ¤íŠ¸ìš© ì¶•ì†Œ
        cache_size_mb=256.0,
        max_workers=2
    )
    
    optimizer = PerformanceOptimizer(config)
    
    # ìµœì í™” ì‹œì‘
    optimizer.start_optimization()
    
    # ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ì‹œë®¬ë ˆì´ì…˜
    print(f"\nğŸ“Š ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ì‹œë®¬ë ˆì´ì…˜...")
    
    pipeline_id = "test_pipeline_001"
    
    for i in range(5):
        metrics = optimizer.collect_performance_metrics(pipeline_id)
        print(f"   ìˆ˜ì§‘ {i+1}: ë©”ëª¨ë¦¬ {metrics.memory_stats.process_memory_gb:.2f}GB, "
              f"CPU {metrics.cpu_percent:.1f}%")
        
        import time
        time.sleep(1)
    
    # ìµœì í™” ë³´ê³ ì„œ ìƒì„±
    report = optimizer.get_optimization_report()
    
    print(f"\nğŸ“‹ ìµœì í™” ë³´ê³ ì„œ:")
    print("="*50)
    
    summary = report['performance_summary']
    print(f"   í‰ê·  ë©”ëª¨ë¦¬: {summary['avg_memory_gb']:.2f}GB")
    print(f"   í‰ê·  CPU: {summary['avg_cpu_percent']:.1f}%")
    print(f"   ìºì‹œ ì ì¤‘ë¥ : {summary['avg_cache_hit_rate']*100:.1f}%")
    print(f"   ë©”ëª¨ë¦¬ ì¶”ì„¸: {summary['memory_trend']}")
    
    print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
    for rec in report['recommendations']:
        print(f"   â€¢ {rec}")
    
    # ë°°í¬ ì¤€ë¹„
    print(f"\nğŸ“¦ ë°°í¬ ì¤€ë¹„...")
    deployment_result = optimizer.prepare_deployment("test_deployment")
    
    print(f"   ë°°í¬ ì¤€ë¹„: {'âœ… ì™„ë£Œ' if deployment_result['deployment_ready'] else 'âŒ ì‹¤íŒ¨'}")
    
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìƒì„¸
    test_results = deployment_result['test_results']
    print(f"\nğŸ§ª ë°°í¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    for test_name, result in test_results.items():
        if test_name != 'overall':
            status = "âœ…" if result.get('passed', False) else "âŒ"
            print(f"   {status} {test_name}: {result.get('message', 'N/A')}")
    
    # ê²°ê³¼ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ
    results_df = optimizer.result_manager.get_results(limit=5)
    print(f"\nğŸ’¾ ì €ì¥ëœ ê²°ê³¼: {len(results_df)}ê°œ")
    
    # ì •ë¦¬
    optimizer.stop_optimization()
    
    print(f"\nğŸ¯ í•µì‹¬ íŠ¹ì§•:")
    print(f"   â€¢ ì‹¤ì‹œê°„ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ë° ìë™ ì •ë¦¬")
    print(f"   â€¢ ì§€ëŠ¥ì  ìºì‹œ ê´€ë¦¬ (TTL, LRU)")
    print(f"   â€¢ ë³‘ë ¬ ì²˜ë¦¬ ì„±ëŠ¥ íŠœë‹")
    print(f"   â€¢ SQLite ê¸°ë°˜ ê²°ê³¼ íˆìŠ¤í† ë¦¬ ê´€ë¦¬")
    print(f"   â€¢ Railway ë°°í¬ ìë™í™”")
    print(f"   â€¢ í—¬ìŠ¤ì²´í¬ ë° ëª¨ë‹ˆí„°ë§ API")

if __name__ == "__main__":
    main()