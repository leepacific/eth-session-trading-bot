#!/usr/bin/env python3
"""
êµ­ì†Œ ì •ë°€ íƒìƒ‰ êµ¬í˜„
- TPE/GP + EI 40ìŠ¤í… ë² ì´ì§€ì•ˆ ìµœì í™”
- ì œì•½ ì¡°ê±´ ìœ„ë°˜ ì‹œ í° ìŒìˆ˜ ë°˜í™˜
- Top-12 â†’ Top-5 í›„ë³´ ì„ ë³„
"""

import time
import warnings
from typing import Callable, Dict, List, Optional, Tuple

import numpy as np
import optuna
import pandas as pd
from optuna.pruners import MedianPruner
from optuna.samplers import TPESampler

warnings.filterwarnings("ignore")

from fast_data_engine import FastDataEngine
from performance_evaluator import PerformanceEvaluator, PerformanceMetrics


class LocalSearchOptimizer:
    def __init__(self, data_engine: FastDataEngine, performance_evaluator: PerformanceEvaluator):
        """êµ­ì†Œ ì •ë°€ íƒìƒ‰ ìµœì í™”ì ì´ˆê¸°í™”"""
        self.data_engine = data_engine
        self.performance_evaluator = performance_evaluator

        # TPE ì„¤ì •
        self.tpe_config = {
            "n_startup_trials": 10,  # ì´ˆê¸° ëœë¤ ì‹œë„
            "n_ei_candidates": 24,  # EI í›„ë³´ ìˆ˜
            "multivariate": True,  # ë‹¤ë³€ëŸ‰ TPE
            "group": True,  # ê·¸ë£¹ ìµœì í™”
        }

        # ë² ì´ì§€ì•ˆ ìµœì í™” ì„¤ì •
        self.bayesian_config = {"n_trials": 40, "timeout": 3600, "n_jobs": 1}  # 40ìŠ¤í…  # 1ì‹œê°„ ì œí•œ  # ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ (ì•ˆì •ì„±)

        print("ğŸ¯ êµ­ì†Œ ì •ë°€ íƒìƒ‰ ìµœì í™”ì ì´ˆê¸°í™”")
        print(f"   ë² ì´ì§€ì•ˆ ìµœì í™”: TPE + EI")
        print(f"   ì‹œë„ íšŸìˆ˜: {self.bayesian_config['n_trials']}íšŒ")
        print(f"   EI í›„ë³´: {self.tpe_config['n_ei_candidates']}ê°œ")

    def create_optuna_study(self, initial_candidates: List[Tuple[Dict, float, PerformanceMetrics]] = None) -> optuna.Study:
        """Optuna ìŠ¤í„°ë”” ìƒì„±"""
        # TPE ìƒ˜í”ŒëŸ¬ ì„¤ì •
        sampler = TPESampler(
            n_startup_trials=self.tpe_config["n_startup_trials"],
            n_ei_candidates=self.tpe_config["n_ei_candidates"],
            multivariate=self.tpe_config["multivariate"],
            group=self.tpe_config["group"],
        )

        # ì¤‘ê°„ê°’ ê¸°ë°˜ ê°€ì§€ì¹˜ê¸°
        pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=10, interval_steps=1)

        # ìŠ¤í„°ë”” ìƒì„±
        study = optuna.create_study(
            direction="maximize", sampler=sampler, pruner=pruner, study_name="local_search_optimization"
        )

        # ì´ˆê¸° í›„ë³´ë“¤ì„ ìŠ¤í„°ë””ì— ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if initial_candidates:
            self._enqueue_initial_candidates(study, initial_candidates)

        return study

    def _enqueue_initial_candidates(self, study: optuna.Study, candidates: List[Tuple[Dict, float, PerformanceMetrics]]):
        """ì´ˆê¸° í›„ë³´ë“¤ì„ ìŠ¤í„°ë”” íì— ì¶”ê°€"""
        print(f"ğŸ“¥ ì´ˆê¸° í›„ë³´ {len(candidates)}ê°œë¥¼ ë² ì´ì§€ì•ˆ ìµœì í™”ì— ì¶”ê°€")

        for params, score, metrics in candidates[:10]:  # ìƒìœ„ 10ê°œë§Œ
            # Optuna í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ íì— ì¶”ê°€
            study.enqueue_trial(params)

    def define_search_space(self, trial: optuna.Trial, focus_region: Dict[str, Tuple[float, float]] = None) -> Dict:
        """íƒìƒ‰ ê³µê°„ ì •ì˜ (êµ­ì†Œ ì˜ì—­ì— ì§‘ì¤‘)"""

        if focus_region:
            # ì§‘ì¤‘ ì˜ì—­ì´ ì§€ì •ëœ ê²½ìš° ì¢ì€ ë²”ìœ„ íƒìƒ‰
            params = {}
            for param_name, (center, radius) in focus_region.items():
                if param_name in ["swing_len", "atr_len", "time_stop_bars", "trend_filter_len"]:
                    # ì •ìˆ˜ íŒŒë¼ë¯¸í„°
                    low = max(1, int(center - radius))
                    high = int(center + radius)
                    params[param_name] = trial.suggest_int(param_name, low, high)
                else:
                    # ì‹¤ìˆ˜ íŒŒë¼ë¯¸í„°
                    low = max(0.01, center - radius)
                    high = center + radius

                    if param_name in ["rr_percentile", "stop_atr_mult"]:
                        # ë¡œê·¸ ìŠ¤ì¼€ì¼
                        params[param_name] = trial.suggest_float(param_name, low, high, log=True)
                    else:
                        # ì„ í˜• ìŠ¤ì¼€ì¼
                        params[param_name] = trial.suggest_float(param_name, low, high)
        else:
            # ì „ì²´ ê³µê°„ íƒìƒ‰ (ê¸°ë³¸ê°’)
            params = {
                "swing_len": trial.suggest_int("swing_len", 3, 8),
                "rr_percentile": trial.suggest_float("rr_percentile", 0.05, 0.5, log=True),
                "disp_mult": trial.suggest_float("disp_mult", 1.0, 2.0),
                "sweep_wick_mult": trial.suggest_float("sweep_wick_mult", 0.3, 0.8),
                "atr_len": trial.suggest_int("atr_len", 20, 60),
                "stop_atr_mult": trial.suggest_float("stop_atr_mult", 0.05, 0.25, log=True),
                "target_r": trial.suggest_float("target_r", 1.5, 4.0),
                "time_stop_bars": trial.suggest_int("time_stop_bars", 2, 10),
                "min_volatility_rank": trial.suggest_float("min_volatility_rank", 0.2, 0.7),
                "session_strength": trial.suggest_float("session_strength", 1.0, 2.5),
                "volume_filter": trial.suggest_float("volume_filter", 1.0, 2.0),
                "trend_filter_len": trial.suggest_int("trend_filter_len", 10, 40),
            }

        return params

    def objective_function(
        self, trial: optuna.Trial, strategy_func: Callable, focus_region: Dict[str, Tuple[float, float]] = None
    ) -> float:
        """ëª©ì  í•¨ìˆ˜ (ì œì•½ ì¡°ê±´ í¬í•¨)"""
        try:
            # íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
            params = self.define_search_space(trial, focus_region)

            # ì „ëµ ì‹¤í–‰ (ì‹œë®¬ë ˆì´ì…˜)
            metrics = self._simulate_strategy_result(params)

            # ì œì•½ ì¡°ê±´ í™•ì¸
            passed, violations = self.performance_evaluator.check_constraints(metrics)

            if not passed:
                # ì œì•½ ì¡°ê±´ ìœ„ë°˜ ì‹œ í° ìŒìˆ˜ ë°˜í™˜
                penalty = -10000 - len(violations) * 1000  # ìœ„ë°˜ í•­ëª© ìˆ˜ì— ë”°ë¼ ì¶”ê°€ íŒ¨ë„í‹°

                # ì¤‘ê°„ ê²°ê³¼ ë³´ê³  (ê°€ì§€ì¹˜ê¸°ìš©)
                trial.report(penalty, step=0)
                if trial.should_prune():
                    raise optuna.TrialPruned()

                return penalty

            # ì ìˆ˜ ê³„ì‚°
            score = self.performance_evaluator.calculate_score(metrics)

            # ì¤‘ê°„ ê²°ê³¼ ë³´ê³ 
            trial.report(score, step=0)
            if trial.should_prune():
                raise optuna.TrialPruned()

            # ì¶”ê°€ ë©”íŠ¸ë¦­ ì €ì¥
            trial.set_user_attr("profit_factor", metrics.profit_factor)
            trial.set_user_attr("win_rate", metrics.win_rate)
            trial.set_user_attr("sortino_ratio", metrics.sortino_ratio)
            trial.set_user_attr("max_drawdown", metrics.max_drawdown)
            trial.set_user_attr("total_trades", metrics.total_trades)

            return score

        except optuna.TrialPruned:
            raise
        except Exception as e:
            print(f"âŒ ëª©ì  í•¨ìˆ˜ ì˜¤ë¥˜: {e}")
            return -10000

    def _simulate_strategy_result(self, params: Dict) -> PerformanceMetrics:
        """ì „ëµ ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜ (ê³ ì¶©ì‹¤ë„)"""
        # íŒŒë¼ë¯¸í„° ê¸°ë°˜ìœ¼ë¡œ ì„±ê³¼ ì‹œë®¬ë ˆì´ì…˜ (ë” ì •êµí•œ ë²„ì „)
        np.random.seed(hash(str(params)) % 2**32)

        # ê±°ë˜ ìˆ˜ (ê³ ì¶©ì‹¤ë„)
        base_trades = 250
        total_trades = base_trades + np.random.randint(-50, 50)

        # íŒŒë¼ë¯¸í„° ì˜í–¥ ë°˜ì˜ (ë” í˜„ì‹¤ì )
        target_r = params.get("target_r", 2.0)
        stop_mult = params.get("stop_atr_mult", 0.1)
        swing_len = params.get("swing_len", 5)

        # ìŠ¹ë¥  (ë³µí•©ì  ì˜í–¥)
        base_win_rate = 0.55

        # target_r ì˜í–¥ (ë†’ì„ìˆ˜ë¡ ìŠ¹ë¥  ê°ì†Œ)
        win_rate_adj = base_win_rate - (target_r - 2.0) * 0.03

        # swing_len ì˜í–¥ (ì§§ì„ìˆ˜ë¡ ë…¸ì´ì¦ˆ ì¦ê°€)
        if swing_len <= 3:
            win_rate_adj -= 0.02
        elif swing_len >= 7:
            win_rate_adj += 0.01

        # stop_mult ì˜í–¥ (ë„ˆë¬´ íƒ€ì´íŠ¸í•˜ë©´ ìŠ¹ë¥  ê°ì†Œ)
        if stop_mult < 0.08:
            win_rate_adj -= 0.03

        win_rate = max(0.35, min(0.75, win_rate_adj + np.random.normal(0, 0.02)))

        # í‰ê·  ì†ìµ (íŒŒë¼ë¯¸í„° ë°˜ì˜)
        avg_win = target_r * 60 * (1 + np.random.normal(0, 0.1))
        avg_loss = -60 * (1 + np.random.normal(0, 0.1))

        # ë³€ë™ì„± (stop_multì— ë”°ë¼ ì¡°ì •)
        win_volatility = abs(avg_win) * (0.15 + stop_mult * 0.5)
        loss_volatility = abs(avg_loss) * (0.15 + stop_mult * 0.5)

        # PnL ìƒì„±
        pnl_data = []
        for _ in range(total_trades):
            if np.random.random() < win_rate:
                pnl = np.random.normal(avg_win, win_volatility)
            else:
                pnl = np.random.normal(avg_loss, loss_volatility)
            pnl_data.append(pnl)

        # DataFrame ìƒì„±
        trades_df = pd.DataFrame({"pnl": pnl_data})

        # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
        metrics = self.performance_evaluator.calculate_metrics(trades_df)

        return metrics

    def calculate_focus_region(
        self, candidates: List[Tuple[Dict, float, PerformanceMetrics]], top_n: int = 5
    ) -> Dict[str, Tuple[float, float]]:
        """ìƒìœ„ í›„ë³´ë“¤ ê¸°ë°˜ìœ¼ë¡œ ì§‘ì¤‘ íƒìƒ‰ ì˜ì—­ ê³„ì‚°"""
        if len(candidates) < 2:
            return None

        # ìƒìœ„ Nê°œ í›„ë³´ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ì§‘
        top_candidates = candidates[:top_n]
        param_values = {}

        for param_name in top_candidates[0][0].keys():
            values = [params[param_name] for params, _, _ in top_candidates]
            param_values[param_name] = values

        # ê° íŒŒë¼ë¯¸í„°ì˜ ì¤‘ì‹¬ê°’ê³¼ ë°˜ê²½ ê³„ì‚°
        focus_region = {}
        for param_name, values in param_values.items():
            center = np.mean(values)
            std = np.std(values)
            radius = max(std * 2, abs(center) * 0.1)  # ìµœì†Œ 10% ë²”ìœ„

            focus_region[param_name] = (center, radius)

        print(f"ğŸ¯ ì§‘ì¤‘ íƒìƒ‰ ì˜ì—­ ê³„ì‚° ì™„ë£Œ (ìƒìœ„ {top_n}ê°œ ê¸°ë°˜)")
        return focus_region

    def run_local_search(
        self,
        strategy_func: Callable,
        initial_candidates: List[Tuple[Dict, float, PerformanceMetrics]] = None,
        use_focus_region: bool = True,
    ) -> List[Tuple[Dict, float, PerformanceMetrics]]:
        """êµ­ì†Œ ì •ë°€ íƒìƒ‰ ì‹¤í–‰"""
        print(f"\nğŸ¯ êµ­ì†Œ ì •ë°€ íƒìƒ‰ ì‹œì‘")
        start_time = time.time()

        # ì§‘ì¤‘ ì˜ì—­ ê³„ì‚°
        focus_region = None
        if use_focus_region and initial_candidates:
            focus_region = self.calculate_focus_region(initial_candidates)

        # Optuna ìŠ¤í„°ë”” ìƒì„±
        study = self.create_optuna_study(initial_candidates)

        # ëª©ì  í•¨ìˆ˜ ë˜í¼
        def objective_wrapper(trial):
            return self.objective_function(trial, strategy_func, focus_region)

        # ë² ì´ì§€ì•ˆ ìµœì í™” ì‹¤í–‰
        try:
            study.optimize(
                objective_wrapper,
                n_trials=self.bayesian_config["n_trials"],
                timeout=self.bayesian_config["timeout"],
                n_jobs=self.bayesian_config["n_jobs"],
                show_progress_bar=True,
            )
        except KeyboardInterrupt:
            print("âš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")

        # ê²°ê³¼ ìˆ˜ì§‘
        results = []
        for trial in study.trials:
            if trial.state == optuna.trial.TrialState.COMPLETE:
                params = trial.params
                score = trial.value

                # ë©”íŠ¸ë¦­ ì¬êµ¬ì„±
                metrics = PerformanceMetrics(
                    total_trades=trial.user_attrs.get("total_trades", 0),
                    win_rate=trial.user_attrs.get("win_rate", 0),
                    profit_factor=trial.user_attrs.get("profit_factor", 0),
                    max_drawdown=trial.user_attrs.get("max_drawdown", 1.0),
                    sortino_ratio=trial.user_attrs.get("sortino_ratio", 0),
                    sharpe_ratio=0,
                    calmar_ratio=0,
                    sqn=0,
                    rr_ratio=0,
                    expectancy=0,
                    mar_ratio=0,
                    total_return=0,
                    annual_return=0,
                    volatility=0,
                    avg_win=0,
                    avg_loss=0,
                )

                results.append((params, score, metrics))

        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        results.sort(key=lambda x: x[1], reverse=True)

        # Top-12 ì„ ë³„
        top_12 = results[:12]

        # ì¶”ê°€ í‰ê°€ í›„ Top-5 ì„ ë³„ (ì‹œë®¬ë ˆì´ì…˜)
        print(f"\nğŸ“Š Top-12 í›„ë³´ ì¶”ê°€ í‰ê°€ ì¤‘...")
        final_candidates = []

        for i, (params, _, _) in enumerate(top_12):
            # ë” ì •êµí•œ í‰ê°€ (ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰ í›„ í‰ê· )
            scores = []
            metrics_list = []

            for seed in range(3):  # 3ë²ˆ ì‹¤í–‰
                np.random.seed(seed + hash(str(params)) % 1000)
                metrics = self._simulate_strategy_result(params)
                score = self.performance_evaluator.calculate_score(metrics)
                scores.append(score)
                metrics_list.append(metrics)

            # í‰ê·  ì ìˆ˜ì™€ ë©”íŠ¸ë¦­
            avg_score = np.mean(scores)
            avg_metrics = self.performance_evaluator.aggregate_results(metrics_list)

            final_candidates.append((params, avg_score, avg_metrics))

        # ìµœì¢… ì •ë ¬ í›„ Top-5
        final_candidates.sort(key=lambda x: x[1], reverse=True)
        top_5 = final_candidates[:5]

        elapsed_time = time.time() - start_time
        print(f"\nâœ… êµ­ì†Œ ì •ë°€ íƒìƒ‰ ì™„ë£Œ ({elapsed_time:.1f}ì´ˆ)")
        print(f"   ì™„ë£Œëœ ì‹œë„: {len(study.trials)}")
        print(f"   ìµœê³  ì ìˆ˜: {study.best_value:.4f}")
        print(f"   ìµœì¢… Top-5 ì„ ë³„ ì™„ë£Œ")

        return top_5

    def print_optimization_progress(self, study: optuna.Study):
        """ìµœì í™” ì§„í–‰ìƒí™© ì¶œë ¥"""
        if len(study.trials) == 0:
            return

        print(f"\nğŸ“ˆ ìµœì í™” ì§„í–‰ìƒí™©:")
        print(f"   ì™„ë£Œëœ ì‹œë„: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}")
        print(f"   ê°€ì§€ì¹˜ê¸°ëœ ì‹œë„: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}")
        print(f"   í˜„ì¬ ìµœê³  ì ìˆ˜: {study.best_value:.4f}")

        if study.best_trial:
            best_params = study.best_trial.params
            key_params = ["target_r", "stop_atr_mult", "swing_len"]
            param_str = ", ".join(
                [
                    (
                        f"{k}: {best_params.get(k, 'N/A'):.3f}"
                        if isinstance(best_params.get(k), float)
                        else f"{k}: {best_params.get(k, 'N/A')}"
                    )
                    for k in key_params
                ]
            )
            print(f"   ìµœê³  íŒŒë¼ë¯¸í„°: {param_str}")


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    # ë°ì´í„° ì—”ì§„ ì´ˆê¸°í™”
    data_engine = FastDataEngine()

    # ì„±ê³¼ í‰ê°€ì ì´ˆê¸°í™”
    performance_evaluator = PerformanceEvaluator()

    # êµ­ì†Œ íƒìƒ‰ ìµœì í™”ì ì´ˆê¸°í™”
    optimizer = LocalSearchOptimizer(data_engine, performance_evaluator)

    # ê°€ìƒì˜ ì „ëµ í•¨ìˆ˜
    def dummy_strategy_func(params):
        return params

    # ê°€ìƒì˜ ì´ˆê¸° í›„ë³´ë“¤
    initial_candidates = [
        ({"target_r": 2.5, "stop_atr_mult": 0.1, "swing_len": 5}, 0.5, None),
        ({"target_r": 3.0, "stop_atr_mult": 0.08, "swing_len": 4}, 0.4, None),
    ]

    # êµ­ì†Œ íƒìƒ‰ ì‹¤í–‰
    results = optimizer.run_local_search(dummy_strategy_func, initial_candidates)

    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“Š êµ­ì†Œ íƒìƒ‰ ê²°ê³¼ (Top-5)")
    print("=" * 60)

    for i, (params, score, metrics) in enumerate(results):
        print(f"\nğŸ† ìˆœìœ„ {i+1}: ì ìˆ˜ {score:.4f}")
        if metrics:
            print(f"   PF: {metrics.profit_factor:.2f}, ìŠ¹ë¥ : {metrics.win_rate:.1%}")
            print(f"   ê±°ë˜ìˆ˜: {metrics.total_trades}, DD: {metrics.max_drawdown:.1%}")


if __name__ == "__main__":
    main()
