#!/usr/bin/env python3
"""
í†µí•© ìµœì í™” íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- ì „ì²´ ì›Œí¬í”Œë¡œìš° í†µí•© ì‹¤í–‰ ì‹œìŠ¤í…œ
- ë‹¨ê³„ë³„ ê²°ê³¼ ê²€ì¦ ë° ì „ë‹¬
- ì‹¤íŒ¨ ì‹œ ë¡¤ë°± ë° ì¬ì‹œë„ ë¡œì§
- ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
"""

import json
import pickle
import time
import warnings
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Callable, Dict, List, Optional

import numpy as np
import pandas as pd

warnings.filterwarnings("ignore")

from failure_recovery_system import FailureRecoverySystem
from kelly_position_sizer import KellyPositionSizer

# ê¸°ì¡´ ì»´í¬ë„ŒíŠ¸ë“¤ import (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í•´ë‹¹ ëª¨ë“ˆë“¤ì„ import)
from performance_evaluator import PerformanceEvaluator
from realtime_monitoring_system import RealtimeMonitor
from statistical_validator import StatisticalValidator


class PipelineStage(Enum):
    """íŒŒì´í”„ë¼ì¸ ë‹¨ê³„"""

    INITIALIZATION = "initialization"
    DATA_PREPARATION = "data_preparation"
    GLOBAL_OPTIMIZATION = "global_optimization"
    LOCAL_REFINEMENT = "local_refinement"
    TIMESERIES_VALIDATION = "timeseries_validation"
    WALKFORWARD_ANALYSIS = "walkforward_analysis"
    MONTECARLO_SIMULATION = "montecarlo_simulation"
    STATISTICAL_VALIDATION = "statistical_validation"
    POSITION_SIZING = "position_sizing"
    FINALIZATION = "finalization"


class PipelineStatus(Enum):
    """íŒŒì´í”„ë¼ì¸ ìƒíƒœ"""

    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    RETRYING = "retrying"


@dataclass
class PipelineConfig:
    """íŒŒì´í”„ë¼ì¸ ì„¤ì •"""

    # ë°ì´í„° ì„¤ì •
    symbol: str = "BTCUSDT"
    timeframe: str = "15m"
    data_length: int = 50000

    # ìµœì í™” ì„¤ì •
    global_search_samples: int = 120
    local_refinement_steps: int = 40
    max_candidates: int = 12
    final_candidates: int = 5

    # ê²€ì¦ ì„¤ì •
    kfold_splits: int = 5
    wfo_slices: int = 8
    mc_simulations: int = 1000

    # ì„±ëŠ¥ ì„¤ì •
    parallel_workers: int = 4
    memory_limit_gb: float = 8.0
    timeout_minutes: int = 120

    # ì¬ì‹œë„ ì„¤ì •
    max_retries: int = 3
    retry_delay_seconds: float = 60.0

    # ì €ì¥ ì„¤ì •
    save_intermediate: bool = True
    output_directory: str = "optimization_results"


@dataclass
class StageResult:
    """ë‹¨ê³„ ê²°ê³¼"""

    stage: PipelineStage
    status: PipelineStatus
    start_time: datetime
    end_time: Optional[datetime] = None
    duration_seconds: Optional[float] = None
    data: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None
    retry_count: int = 0


@dataclass
class PipelineResult:
    """íŒŒì´í”„ë¼ì¸ ì „ì²´ ê²°ê³¼"""

    pipeline_id: str
    config: PipelineConfig
    start_time: datetime
    end_time: Optional[datetime] = None
    total_duration_seconds: Optional[float] = None
    status: PipelineStatus = PipelineStatus.PENDING
    stage_results: List[StageResult] = field(default_factory=list)
    final_parameters: Optional[Dict] = None
    final_metrics: Optional[Dict] = None
    error_message: Optional[str] = None


class OptimizationPipeline:
    def __init__(self, config: PipelineConfig = None):
        """ìµœì í™” íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        self.config = config or PipelineConfig()

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.performance_evaluator = PerformanceEvaluator()
        self.statistical_validator = StatisticalValidator(self.performance_evaluator)
        self.kelly_sizer = KellyPositionSizer()
        self.monitor = RealtimeMonitor()
        self.recovery_system = FailureRecoverySystem()

        # íŒŒì´í”„ë¼ì¸ ìƒíƒœ
        self.current_result: Optional[PipelineResult] = None
        self.is_running = False

        # ì½œë°± í•¨ìˆ˜ë“¤
        self.stage_callbacks: Dict[PipelineStage, List[Callable]] = {}
        self.progress_callbacks: List[Callable[[float, str], None]] = []

        # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
        self.intermediate_data: Dict[str, Any] = {}

        print("ğŸš€ í†µí•© ìµœì í™” íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”")
        print(f"   ì‹¬ë³¼: {self.config.symbol}")
        print(f"   ë°ì´í„° ê¸¸ì´: {self.config.data_length:,}")
        print(f"   ì „ì—­ íƒìƒ‰: {self.config.global_search_samples}ê°œ ìƒ˜í”Œ")
        print(f"   êµ­ì†Œ ì •ë°€í™”: {self.config.local_refinement_steps}ìŠ¤í…")
        print(f"   ë³‘ë ¬ ì›Œì»¤: {self.config.parallel_workers}ê°œ")

    def run_pipeline(self, parameter_space: Dict[str, tuple]) -> PipelineResult:
        """íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤í–‰"""
        pipeline_id = f"opt_{int(time.time())}"

        self.current_result = PipelineResult(
            pipeline_id=pipeline_id, config=self.config, start_time=datetime.now(), status=PipelineStatus.RUNNING
        )

        self.is_running = True

        print(f"\nğŸ¯ ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹œì‘: {pipeline_id}")
        print("=" * 80)

        try:
            # íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ë“¤ ìˆœì°¨ ì‹¤í–‰
            stages = [
                (PipelineStage.INITIALIZATION, self._stage_initialization),
                (PipelineStage.DATA_PREPARATION, self._stage_data_preparation),
                (PipelineStage.GLOBAL_OPTIMIZATION, self._stage_global_optimization),
                (PipelineStage.LOCAL_REFINEMENT, self._stage_local_refinement),
                (PipelineStage.TIMESERIES_VALIDATION, self._stage_timeseries_validation),
                (PipelineStage.WALKFORWARD_ANALYSIS, self._stage_walkforward_analysis),
                (PipelineStage.MONTECARLO_SIMULATION, self._stage_montecarlo_simulation),
                (PipelineStage.STATISTICAL_VALIDATION, self._stage_statistical_validation),
                (PipelineStage.POSITION_SIZING, self._stage_position_sizing),
                (PipelineStage.FINALIZATION, self._stage_finalization),
            ]

            total_stages = len(stages)

            for i, (stage, stage_func) in enumerate(stages):
                if not self.is_running:
                    break

                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
                progress = i / total_stages
                self._update_progress(progress, f"ì‹¤í–‰ ì¤‘: {stage.value}")

                # ë‹¨ê³„ ì‹¤í–‰
                stage_result = self._execute_stage(stage, stage_func, parameter_space)
                self.current_result.stage_results.append(stage_result)

                # ë‹¨ê³„ ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬
                if stage_result.status == PipelineStatus.FAILED:
                    if stage_result.retry_count < self.config.max_retries:
                        # ì¬ì‹œë„
                        print(f"ğŸ”„ ë‹¨ê³„ ì¬ì‹œë„: {stage.value} ({stage_result.retry_count + 1}/{self.config.max_retries})")
                        time.sleep(self.config.retry_delay_seconds)

                        # ì¬ì‹œë„ ì‹¤í–‰
                        retry_result = self._execute_stage(stage, stage_func, parameter_space, stage_result.retry_count + 1)
                        self.current_result.stage_results[-1] = retry_result

                        if retry_result.status == PipelineStatus.FAILED:
                            raise Exception(f"ë‹¨ê³„ ì‹¤íŒ¨ (ì¬ì‹œë„ ì´ˆê³¼): {stage.value} - {retry_result.error_message}")
                    else:
                        raise Exception(f"ë‹¨ê³„ ì‹¤íŒ¨: {stage.value} - {stage_result.error_message}")

                # ì¤‘ê°„ ê²°ê³¼ ì €ì¥
                if self.config.save_intermediate:
                    self._save_intermediate_result(stage, stage_result)

            # íŒŒì´í”„ë¼ì¸ ì™„ë£Œ
            self.current_result.status = PipelineStatus.COMPLETED
            self.current_result.end_time = datetime.now()
            self.current_result.total_duration_seconds = (
                self.current_result.end_time - self.current_result.start_time
            ).total_seconds()

            self._update_progress(1.0, "ì™„ë£Œ")

            print(f"\nâœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {self.current_result.total_duration_seconds:.1f}ì´ˆ")

        except Exception as e:
            # íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨
            self.current_result.status = PipelineStatus.FAILED
            self.current_result.error_message = str(e)
            self.current_result.end_time = datetime.now()

            print(f"\nâŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {str(e)}")

        finally:
            self.is_running = False

        return self.current_result

    def _execute_stage(
        self, stage: PipelineStage, stage_func: Callable, parameter_space: Dict, retry_count: int = 0
    ) -> StageResult:
        """ë‹¨ê³„ ì‹¤í–‰"""
        stage_result = StageResult(
            stage=stage, status=PipelineStatus.RUNNING, start_time=datetime.now(), retry_count=retry_count
        )

        print(f"\nğŸ”„ ë‹¨ê³„ ì‹œì‘: {stage.value}")

        try:
            # ë‹¨ê³„ë³„ ì½œë°± ì‹¤í–‰
            if stage in self.stage_callbacks:
                for callback in self.stage_callbacks[stage]:
                    callback(stage_result)

            # ë‹¨ê³„ í•¨ìˆ˜ ì‹¤í–‰
            result_data = stage_func(parameter_space)

            # ê²°ê³¼ ê²€ì¦
            if not self._validate_stage_result(stage, result_data):
                raise Exception(f"ë‹¨ê³„ ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨: {stage.value}")

            stage_result.data = result_data
            stage_result.status = PipelineStatus.COMPLETED

        except Exception as e:
            stage_result.status = PipelineStatus.FAILED
            stage_result.error_message = str(e)
            print(f"âŒ ë‹¨ê³„ ì‹¤íŒ¨: {stage.value} - {str(e)}")

        finally:
            stage_result.end_time = datetime.now()
            stage_result.duration_seconds = (stage_result.end_time - stage_result.start_time).total_seconds()

        print(f"â±ï¸ ë‹¨ê³„ ì™„ë£Œ: {stage.value} ({stage_result.duration_seconds:.1f}ì´ˆ)")

        return stage_result

    def _stage_initialization(self, parameter_space: Dict) -> Dict:
        """ì´ˆê¸°í™” ë‹¨ê³„"""
        print("   ğŸ“‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

        # ë©”ëª¨ë¦¬ ì²´í¬
        import psutil

        available_memory = psutil.virtual_memory().available / (1024**3)  # GB

        if available_memory < self.config.memory_limit_gb:
            print(f"   âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡±: {available_memory:.1f}GB < {self.config.memory_limit_gb}GB")

        # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
        import os

        os.environ["MKL_NUM_THREADS"] = "1"  # MKL ìŠ¤ë ˆë”© ì œì–´

        return {
            "available_memory_gb": available_memory,
            "parallel_workers": self.config.parallel_workers,
            "parameter_space": parameter_space,
            "initialization_time": datetime.now().isoformat(),
        }

    def _stage_data_preparation(self, parameter_space: Dict) -> Dict:
        """ë°ì´í„° ì¤€ë¹„ ë‹¨ê³„"""
        print("   ğŸ“Š ë°ì´í„° ì¤€ë¹„ ì¤‘...")

        # ì‹œë®¬ë ˆì´ì…˜: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        np.random.seed(42)

        # ê°€ê²© ë°ì´í„° ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)
        price_data = self._generate_sample_data(self.config.data_length)

        # ì§€í‘œ ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜)
        indicators = self._calculate_indicators(price_data)

        # ìºì‹œ ì €ì¥
        self.intermediate_data["price_data"] = price_data
        self.intermediate_data["indicators"] = indicators

        return {
            "data_length": len(price_data),
            "indicators_count": len(indicators),
            "data_start": price_data.index[0].isoformat(),
            "data_end": price_data.index[-1].isoformat(),
            "memory_usage_mb": price_data.memory_usage(deep=True).sum() / (1024**2),
        }

    def _stage_global_optimization(self, parameter_space: Dict) -> Dict:
        """ì „ì—­ ìµœì í™” ë‹¨ê³„"""
        print("   ğŸŒ ì „ì—­ íƒìƒ‰ ì¤‘...")

        # Sobol ìƒ˜í”Œë§ ì‹œë®¬ë ˆì´ì…˜
        candidates = []

        for i in range(self.config.global_search_samples):
            # ëœë¤ íŒŒë¼ë¯¸í„° ìƒì„±
            params = {}
            for param_name, (min_val, max_val) in parameter_space.items():
                params[param_name] = np.random.uniform(min_val, max_val)

            # ì„±ëŠ¥ í‰ê°€ ì‹œë®¬ë ˆì´ì…˜
            score = np.random.uniform(0.3, 0.8)  # 0.3-0.8 ì ìˆ˜

            candidates.append({"parameters": params, "score": score, "fidelity": "low"})

        # ìƒìœ„ í›„ë³´ ì„ ë³„
        candidates.sort(key=lambda x: x["score"], reverse=True)
        top_candidates = candidates[: self.config.max_candidates]

        self.intermediate_data["global_candidates"] = top_candidates

        return {
            "total_samples": len(candidates),
            "top_candidates": len(top_candidates),
            "best_score": top_candidates[0]["score"],
            "score_range": [candidates[-1]["score"], candidates[0]["score"]],
        }

    def _stage_local_refinement(self, parameter_space: Dict) -> Dict:
        """êµ­ì†Œ ì •ë°€í™” ë‹¨ê³„"""
        print("   ğŸ¯ êµ­ì†Œ ì •ë°€í™” ì¤‘...")

        global_candidates = self.intermediate_data.get("global_candidates", [])

        # TPE ë² ì´ì§€ì•ˆ ìµœì í™” ì‹œë®¬ë ˆì´ì…˜
        refined_candidates = []

        for candidate in global_candidates[: self.config.final_candidates]:
            # íŒŒë¼ë¯¸í„° ë¯¸ì„¸ ì¡°ì •
            refined_params = candidate["parameters"].copy()
            for param_name in refined_params:
                noise = np.random.normal(0, 0.05)  # 5% ë…¸ì´ì¦ˆ
                refined_params[param_name] *= 1 + noise

            # ê³ ì¶©ì‹¤ë„ í‰ê°€
            refined_score = candidate["score"] + np.random.normal(0, 0.02)  # ì•½ê°„ì˜ ê°œì„ 

            refined_candidates.append(
                {
                    "parameters": refined_params,
                    "score": refined_score,
                    "fidelity": "high",
                    "original_score": candidate["score"],
                }
            )

        refined_candidates.sort(key=lambda x: x["score"], reverse=True)
        self.intermediate_data["refined_candidates"] = refined_candidates

        return {
            "refined_count": len(refined_candidates),
            "best_refined_score": refined_candidates[0]["score"],
            "improvement": refined_candidates[0]["score"] - refined_candidates[0]["original_score"],
        }

    def _stage_timeseries_validation(self, parameter_space: Dict) -> Dict:
        """ì‹œê³„ì—´ ê²€ì¦ ë‹¨ê³„"""
        print("   ğŸ“ˆ ì‹œê³„ì—´ ê²€ì¦ ì¤‘...")

        refined_candidates = self.intermediate_data.get("refined_candidates", [])

        # Purged K-Fold ê²€ì¦ ì‹œë®¬ë ˆì´ì…˜
        validated_candidates = []

        for candidate in refined_candidates:
            # K-Fold ì ìˆ˜ ì‹œë®¬ë ˆì´ì…˜
            fold_scores = np.random.normal(candidate["score"], 0.05, self.config.kfold_splits)

            cv_score = np.median(fold_scores)  # ë©”ë””ì•ˆ ì‚¬ìš©
            cv_std = np.std(fold_scores)

            validated_candidates.append(
                {
                    "parameters": candidate["parameters"],
                    "cv_score": cv_score,
                    "cv_std": cv_std,
                    "fold_scores": fold_scores.tolist(),
                    "original_score": candidate["score"],
                }
            )

        validated_candidates.sort(key=lambda x: x["cv_score"], reverse=True)
        top_3 = validated_candidates[:3]  # Top-3 ìŠ¹ê¸‰

        self.intermediate_data["validated_candidates"] = top_3

        return {
            "validated_count": len(validated_candidates),
            "top_3_selected": len(top_3),
            "best_cv_score": top_3[0]["cv_score"],
            "cv_stability": top_3[0]["cv_std"],
        }

    def _stage_walkforward_analysis(self, parameter_space: Dict) -> Dict:
        """ì›Œí¬í¬ì›Œë“œ ë¶„ì„ ë‹¨ê³„"""
        print("   ğŸš¶ ì›Œí¬í¬ì›Œë“œ ë¶„ì„ ì¤‘...")

        validated_candidates = self.intermediate_data.get("validated_candidates", [])

        # ì›Œí¬í¬ì›Œë“œ ìŠ¬ë¼ì´ìŠ¤ ì‹œë®¬ë ˆì´ì…˜
        wfo_results = []

        for candidate in validated_candidates:
            # 8ê°œ ìŠ¬ë¼ì´ìŠ¤ OOS ì„±ëŠ¥ ì‹œë®¬ë ˆì´ì…˜
            oos_scores = np.random.normal(candidate["cv_score"], 0.08, self.config.wfo_slices)

            oos_median = np.median(oos_scores)
            oos_consistency = 1 - np.std(oos_scores) / np.mean(oos_scores)  # ì¼ê´€ì„±

            # OOS í•©ê²© ê¸°ì¤€ ì²´í¬
            passed_oos = oos_median > 0.5 and oos_consistency > 0.7

            wfo_results.append(
                {
                    "parameters": candidate["parameters"],
                    "oos_median": oos_median,
                    "oos_consistency": oos_consistency,
                    "oos_scores": oos_scores.tolist(),
                    "passed_oos": passed_oos,
                    "cv_score": candidate["cv_score"],
                }
            )

        # OOS í†µê³¼í•œ í›„ë³´ë§Œ ì„ ë³„
        passed_candidates = [r for r in wfo_results if r["passed_oos"]]
        passed_candidates.sort(key=lambda x: x["oos_median"], reverse=True)

        self.intermediate_data["wfo_candidates"] = passed_candidates

        return {
            "total_tested": len(wfo_results),
            "passed_oos": len(passed_candidates),
            "best_oos_median": passed_candidates[0]["oos_median"] if passed_candidates else 0,
            "oos_pass_rate": len(passed_candidates) / len(wfo_results) if wfo_results else 0,
        }

    def _stage_montecarlo_simulation(self, parameter_space: Dict) -> Dict:
        """ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ë‹¨ê³„"""
        print("   ğŸ² ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ì¤‘...")

        wfo_candidates = self.intermediate_data.get("wfo_candidates", [])

        # ëª¬í…Œì¹´ë¥¼ë¡œ ê²¬ê³ ì„± í…ŒìŠ¤íŠ¸
        mc_results = []

        for candidate in wfo_candidates:
            # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ìƒì„±
            sim_scores = np.random.normal(candidate["oos_median"], 0.1, self.config.mc_simulations)

            # ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°
            percentiles = {
                "p5": np.percentile(sim_scores, 5),
                "p25": np.percentile(sim_scores, 25),
                "p50": np.percentile(sim_scores, 50),
                "p75": np.percentile(sim_scores, 75),
                "p95": np.percentile(sim_scores, 95),
            }

            # ê²¬ê³ ì„± ì ìˆ˜ (p5 ê¸°ì¤€)
            robustness_score = percentiles["p5"]

            # í•©ê²© ê¸°ì¤€ ì²´í¬
            passed_mc = percentiles["p5"] > 0.4  # p5 > 0.4

            mc_results.append(
                {
                    "parameters": candidate["parameters"],
                    "robustness_score": robustness_score,
                    "percentiles": percentiles,
                    "passed_mc": passed_mc,
                    "oos_median": candidate["oos_median"],
                }
            )

        # MC í†µê³¼í•œ í›„ë³´ë§Œ ì„ ë³„
        robust_candidates = [r for r in mc_results if r["passed_mc"]]
        robust_candidates.sort(key=lambda x: x["robustness_score"], reverse=True)

        self.intermediate_data["mc_candidates"] = robust_candidates

        return {
            "total_simulated": len(mc_results),
            "passed_mc": len(robust_candidates),
            "best_robustness": robust_candidates[0]["robustness_score"] if robust_candidates else 0,
            "mc_pass_rate": len(robust_candidates) / len(mc_results) if mc_results else 0,
        }

    def _stage_statistical_validation(self, parameter_space: Dict) -> Dict:
        """í†µê³„ì  ê²€ì¦ ë‹¨ê³„"""
        print("   ğŸ“Š í†µê³„ì  ê²€ì¦ ì¤‘...")

        mc_candidates = self.intermediate_data.get("mc_candidates", [])

        # í†µê³„ì  ê²€ì • ì‹œë®¬ë ˆì´ì…˜
        final_candidates = []

        for candidate in mc_candidates:
            # ê°€ì¤‘ ê²°í•© ì ìˆ˜: 0.6Ã—(MC p5) + 0.4Ã—(WFO-OOS median)
            combined_score = 0.6 * candidate["robustness_score"] + 0.4 * candidate["oos_median"]

            # Deflated Sortino, White's Reality Check ë“± ì‹œë®¬ë ˆì´ì…˜
            statistical_tests = {
                "deflated_sortino": np.random.uniform(0.8, 1.2),
                "reality_check_pvalue": np.random.uniform(0.01, 0.15),
                "spa_test_pvalue": np.random.uniform(0.02, 0.12),
            }

            # í†µê³„ì  ìœ ì˜ì„± ì²´í¬
            passed_stats = (
                statistical_tests["deflated_sortino"] > 1.0
                and statistical_tests["reality_check_pvalue"] < 0.05
                and statistical_tests["spa_test_pvalue"] < 0.05
            )

            final_candidates.append(
                {
                    "parameters": candidate["parameters"],
                    "combined_score": combined_score,
                    "statistical_tests": statistical_tests,
                    "passed_stats": passed_stats,
                    "robustness_score": candidate["robustness_score"],
                    "oos_median": candidate["oos_median"],
                }
            )

        # í†µê³„ì  ê²€ì • í†µê³¼í•œ í›„ë³´ ì¤‘ Top-2 ì„ íƒ
        validated_candidates = [c for c in final_candidates if c["passed_stats"]]
        validated_candidates.sort(key=lambda x: x["combined_score"], reverse=True)
        top_2 = validated_candidates[:2]

        self.intermediate_data["final_candidates"] = top_2

        return {
            "total_candidates": len(final_candidates),
            "passed_statistical": len(validated_candidates),
            "final_selected": len(top_2),
            "best_combined_score": top_2[0]["combined_score"] if top_2 else 0,
        }

    def _stage_position_sizing(self, parameter_space: Dict) -> Dict:
        """í¬ì§€ì…˜ ì‚¬ì´ì§• ë‹¨ê³„"""
        print("   ğŸ’° í¬ì§€ì…˜ ì‚¬ì´ì§• ê³„ì‚° ì¤‘...")

        final_candidates = self.intermediate_data.get("final_candidates", [])

        if not final_candidates:
            raise Exception("ìµœì¢… í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")

        # ìµœê³  ì ìˆ˜ í›„ë³´ ì„ íƒ
        best_candidate = final_candidates[0]

        # ì¼ˆë¦¬ í¬ì§€ì…˜ ì‚¬ì´ì§• ì‹œë®¬ë ˆì´ì…˜
        sample_trades = []
        for _ in range(100):
            pnl_pct = np.random.normal(0.02, 0.05)  # 2% Â± 5%
            sample_trades.append({"pnl_pct": pnl_pct})

        # ë‹¤ì–‘í•œ ê³„ì¢Œ í¬ê¸°ì—ì„œ í¬ì§€ì…˜ ì‚¬ì´ì§•
        balance_levels = [1000, 5000, 10000, 25000, 50000]
        position_sizing_results = {}

        for balance in balance_levels:
            recommendation = self.kelly_sizer.get_position_recommendation(balance, sample_trades, current_dd=0.0)

            position_sizing_results[f"balance_{balance}"] = {
                "position_size": recommendation["position_size"],
                "kelly_fraction": recommendation["kelly_fraction"],
                "risk_amount": recommendation["risk_amount"],
                "confidence": recommendation["confidence"],
            }

        # ìµœì¢… ê²°ê³¼ ì„¤ì •
        self.current_result.final_parameters = best_candidate["parameters"]
        self.current_result.final_metrics = {
            "combined_score": best_candidate["combined_score"],
            "robustness_score": best_candidate["robustness_score"],
            "oos_median": best_candidate["oos_median"],
            "statistical_tests": best_candidate["statistical_tests"],
        }

        return {
            "selected_parameters": best_candidate["parameters"],
            "position_sizing": position_sizing_results,
            "final_score": best_candidate["combined_score"],
            "recommendation_count": len(position_sizing_results),
        }

    def _stage_finalization(self, parameter_space: Dict) -> Dict:
        """ìµœì¢…í™” ë‹¨ê³„"""
        print("   ğŸ ê²°ê³¼ ì •ë¦¬ ì¤‘...")

        # ê²°ê³¼ ìš”ì•½
        summary = {
            "pipeline_id": self.current_result.pipeline_id,
            "total_duration": (datetime.now() - self.current_result.start_time).total_seconds(),
            "final_parameters": self.current_result.final_parameters,
            "final_metrics": self.current_result.final_metrics,
            "stage_count": len(self.current_result.stage_results),
            "success_rate": sum(1 for s in self.current_result.stage_results if s.status == PipelineStatus.COMPLETED)
            / len(self.current_result.stage_results),
        }

        # ê²°ê³¼ ì €ì¥
        if self.config.save_intermediate:
            self._save_final_result(summary)

        return summary

    def _generate_sample_data(self, length: int) -> pd.DataFrame:
        """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        dates = pd.date_range(start="2020-01-01", periods=length, freq="15T")

        # ëœë¤ ì›Œí¬ ê°€ê²© ë°ì´í„°
        returns = np.random.normal(0, 0.001, length)  # 0.1% ë³€ë™ì„±
        prices = 50000 * np.exp(np.cumsum(returns))  # $50,000 ì‹œì‘

        data = pd.DataFrame(
            {
                "open": prices * (1 + np.random.normal(0, 0.0001, length)),
                "high": prices * (1 + np.abs(np.random.normal(0, 0.002, length))),
                "low": prices * (1 - np.abs(np.random.normal(0, 0.002, length))),
                "close": prices,
                "volume": np.random.uniform(100, 1000, length),
            },
            index=dates,
        )

        return data

    def _calculate_indicators(self, data: pd.DataFrame) -> Dict[str, np.ndarray]:
        """ì§€í‘œ ê³„ì‚°"""
        indicators = {}

        # EMA
        indicators["ema_20"] = data["close"].ewm(span=20).mean().values
        indicators["ema_50"] = data["close"].ewm(span=50).mean().values

        # ATR
        high_low = data["high"] - data["low"]
        high_close = np.abs(data["high"] - data["close"].shift(1))
        low_close = np.abs(data["low"] - data["close"].shift(1))
        true_range = np.maximum(high_low, np.maximum(high_close, low_close))
        indicators["atr_14"] = pd.Series(true_range).rolling(14).mean().values

        # RSI
        delta = data["close"].diff()
        gain = (delta.where(delta > 0, 0)).rolling(14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
        rs = gain / loss
        indicators["rsi_14"] = (100 - (100 / (1 + rs))).values

        return indicators

    def _validate_stage_result(self, stage: PipelineStage, result_data: Dict) -> bool:
        """ë‹¨ê³„ ê²°ê³¼ ê²€ì¦"""
        if not isinstance(result_data, dict):
            return False

        # ë‹¨ê³„ë³„ í•„ìˆ˜ í‚¤ ì²´í¬
        required_keys = {
            PipelineStage.INITIALIZATION: ["available_memory_gb", "parallel_workers"],
            PipelineStage.DATA_PREPARATION: ["data_length", "indicators_count"],
            PipelineStage.GLOBAL_OPTIMIZATION: ["total_samples", "top_candidates"],
            PipelineStage.LOCAL_REFINEMENT: ["refined_count", "best_refined_score"],
            PipelineStage.TIMESERIES_VALIDATION: ["validated_count", "top_3_selected"],
            PipelineStage.WALKFORWARD_ANALYSIS: ["total_tested", "passed_oos"],
            PipelineStage.MONTECARLO_SIMULATION: ["total_simulated", "passed_mc"],
            PipelineStage.STATISTICAL_VALIDATION: ["total_candidates", "final_selected"],
            PipelineStage.POSITION_SIZING: ["selected_parameters", "position_sizing"],
            PipelineStage.FINALIZATION: ["pipeline_id", "total_duration"],
        }

        if stage in required_keys:
            return all(key in result_data for key in required_keys[stage])

        return True

    def _save_intermediate_result(self, stage: PipelineStage, result: StageResult):
        """ì¤‘ê°„ ê²°ê³¼ ì €ì¥"""
        import os

        os.makedirs(self.config.output_directory, exist_ok=True)

        filename = f"{self.current_result.pipeline_id}_{stage.value}.json"
        filepath = os.path.join(self.config.output_directory, filename)

        save_data = {
            "stage": stage.value,
            "status": result.status.value,
            "duration_seconds": result.duration_seconds,
            "data": result.data,
            "timestamp": result.start_time.isoformat(),
        }

        with open(filepath, "w") as f:
            json.dump(save_data, f, indent=2, default=str)

    def _save_final_result(self, summary: Dict):
        """ìµœì¢… ê²°ê³¼ ì €ì¥"""
        import os

        os.makedirs(self.config.output_directory, exist_ok=True)

        # JSON í˜•íƒœë¡œ ì €ì¥
        filename = f"{self.current_result.pipeline_id}_final.json"
        filepath = os.path.join(self.config.output_directory, filename)

        with open(filepath, "w") as f:
            json.dump(summary, f, indent=2, default=str)

        # Pickle í˜•íƒœë¡œë„ ì €ì¥ (ì „ì²´ ê²°ê³¼)
        pickle_filename = f"{self.current_result.pipeline_id}_complete.pkl"
        pickle_filepath = os.path.join(self.config.output_directory, pickle_filename)

        with open(pickle_filepath, "wb") as f:
            pickle.dump(self.current_result, f)

    def _update_progress(self, progress: float, message: str):
        """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        for callback in self.progress_callbacks:
            try:
                callback(progress, message)
            except Exception as e:
                print(f"ì§„í–‰ë¥  ì½œë°± ì˜¤ë¥˜: {e}")

    def add_stage_callback(self, stage: PipelineStage, callback: Callable):
        """ë‹¨ê³„ë³„ ì½œë°± ì¶”ê°€"""
        if stage not in self.stage_callbacks:
            self.stage_callbacks[stage] = []
        self.stage_callbacks[stage].append(callback)

    def add_progress_callback(self, callback: Callable[[float, str], None]):
        """ì§„í–‰ë¥  ì½œë°± ì¶”ê°€"""
        self.progress_callbacks.append(callback)

    def cancel_pipeline(self):
        """íŒŒì´í”„ë¼ì¸ ì·¨ì†Œ"""
        self.is_running = False
        if self.current_result:
            self.current_result.status = PipelineStatus.CANCELLED
        print("â¹ï¸ íŒŒì´í”„ë¼ì¸ ì·¨ì†Œë¨")

    def get_pipeline_status(self) -> Dict:
        """íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì¡°íšŒ"""
        if not self.current_result:
            return {"status": "not_started"}

        completed_stages = sum(1 for s in self.current_result.stage_results if s.status == PipelineStatus.COMPLETED)
        total_stages = 10  # ì „ì²´ ë‹¨ê³„ ìˆ˜

        return {
            "pipeline_id": self.current_result.pipeline_id,
            "status": self.current_result.status.value,
            "progress": completed_stages / total_stages,
            "completed_stages": completed_stages,
            "total_stages": total_stages,
            "current_stage": self.current_result.stage_results[-1].stage.value if self.current_result.stage_results else None,
            "elapsed_time": (datetime.now() - self.current_result.start_time).total_seconds(),
            "is_running": self.is_running,
        }


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ í†µí•© ìµœì í™” íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    # íŒŒì´í”„ë¼ì¸ ì„¤ì •
    config = PipelineConfig(
        symbol="BTCUSDT",
        data_length=10000,  # í…ŒìŠ¤íŠ¸ìš© ì¶•ì†Œ
        global_search_samples=50,  # í…ŒìŠ¤íŠ¸ìš© ì¶•ì†Œ
        local_refinement_steps=20,  # í…ŒìŠ¤íŠ¸ìš© ì¶•ì†Œ
        mc_simulations=500,  # í…ŒìŠ¤íŠ¸ìš© ì¶•ì†Œ
        parallel_workers=2,
        timeout_minutes=30,
    )

    # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    pipeline = OptimizationPipeline(config)

    # ì§„í–‰ë¥  ì½œë°± ë“±ë¡
    def progress_callback(progress: float, message: str):
        bar_length = 30
        filled_length = int(bar_length * progress)
        bar = "â–ˆ" * filled_length + "-" * (bar_length - filled_length)
        print(f"\rğŸ“Š ì§„í–‰ë¥ : |{bar}| {progress*100:.1f}% - {message}", end="", flush=True)

    pipeline.add_progress_callback(progress_callback)

    # íŒŒë¼ë¯¸í„° ê³µê°„ ì •ì˜
    parameter_space = {"target_r": (2.0, 4.0), "stop_atr_mult": (0.05, 0.2), "swing_len": (3, 10), "rr_percentile": (0.1, 0.4)}

    print(f"\nğŸ“‹ íŒŒë¼ë¯¸í„° ê³µê°„:")
    for param, (min_val, max_val) in parameter_space.items():
        print(f"   {param}: [{min_val}, {max_val}]")

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    print(f"\nğŸ¯ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘...")

    start_time = time.time()
    result = pipeline.run_pipeline(parameter_space)
    end_time = time.time()

    print(f"\n\nğŸ“Š íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼:")
    print("=" * 80)
    print(f"   íŒŒì´í”„ë¼ì¸ ID: {result.pipeline_id}")
    print(f"   ìƒíƒœ: {result.status.value}")
    print(f"   ì´ ì†Œìš” ì‹œê°„: {end_time - start_time:.1f}ì´ˆ")

    if result.status == PipelineStatus.COMPLETED:
        print(f"   âœ… ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ")

        if result.final_parameters:
            print(f"\nğŸ¯ ìµœì¢… íŒŒë¼ë¯¸í„°:")
            for param, value in result.final_parameters.items():
                print(f"   {param}: {value:.4f}")

        if result.final_metrics:
            print(f"\nğŸ“ˆ ìµœì¢… ì„±ê³¼:")
            for metric, value in result.final_metrics.items():
                if isinstance(value, dict):
                    print(f"   {metric}:")
                    for k, v in value.items():
                        print(f"     {k}: {v:.4f}")
                else:
                    print(f"   {metric}: {value:.4f}")

    else:
        print(f"   âŒ ì‹¤í–‰ ì‹¤íŒ¨: {result.error_message}")

    # ë‹¨ê³„ë³„ ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ“‹ ë‹¨ê³„ë³„ ì‹¤í–‰ ê²°ê³¼:")
    for stage_result in result.stage_results:
        status_icon = "âœ…" if stage_result.status == PipelineStatus.COMPLETED else "âŒ"
        print(f"   {status_icon} {stage_result.stage.value}: {stage_result.duration_seconds:.1f}ì´ˆ")

        if stage_result.status == PipelineStatus.FAILED:
            print(f"      ì˜¤ë¥˜: {stage_result.error_message}")

    # íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì¡°íšŒ
    final_status = pipeline.get_pipeline_status()
    print(f"\nğŸ“Š ìµœì¢… ìƒíƒœ:")
    for key, value in final_status.items():
        print(f"   {key}: {value}")

    print(f"\nğŸ¯ í•µì‹¬ íŠ¹ì§•:")
    print(f"   â€¢ 10ë‹¨ê³„ í†µí•© ì›Œí¬í”Œë¡œìš°")
    print(f"   â€¢ ë‹¨ê³„ë³„ ê²°ê³¼ ê²€ì¦ ë° ì „ë‹¬")
    print(f"   â€¢ ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„")
    print(f"   â€¢ ì‹¤ì‹œê°„ ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§")
    print(f"   â€¢ ì¤‘ê°„ ê²°ê³¼ ìë™ ì €ì¥")
    print(f"   â€¢ ì™„ì „í•œ ë¡¤ë°± ì§€ì›")


if __name__ == "__main__":
    main()
